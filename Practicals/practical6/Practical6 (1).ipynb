{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer Architecture Implementation (PyTorch)"
      ],
      "metadata": {
        "id": "hG3xPgfbt_gP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports essential libraries for mathematical operations, type hints, and PyTorch modules to build and manage neural networks."
      ],
      "metadata": {
        "id": "CPBsrVJEk2ol"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7X820vIltzgy"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from typing import Optional\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scaled Dot-Product Attention\n"
      ],
      "metadata": {
        "id": "Qys7ONkazWZ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defines the Scaled Dot-Product Attention class, which calculates attention scores between queries (Q) and keys (K), applies a mask if provided, normalizes with softmax, and uses the scores to weight the values (V) to produce the final context and attention outputs."
      ],
      "metadata": {
        "id": "m3MyWBQdk8kX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ScaledDotProductAttention(nn.Module):\n",
        "    \"\"\"Compute scaled dot-product attention.\n",
        "\n",
        "\n",
        "    Inputs:\n",
        "        Q: (..., seq_len_q, d_k)\n",
        "        K: (..., seq_len_k, d_k)\n",
        "        V: (..., seq_len_v, d_v) where seq_len_k == seq_len_v\n",
        "        mask: (..., seq_len_q, seq_len_k) with 0 for allowed positions and 1 (or -inf) for masked.\n",
        "\n",
        "\n",
        "    Returns:\n",
        "        context: (..., seq_len_q, d_v)\n",
        "        attn: (..., seq_len_q, seq_len_k)\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    def __init__(self, dropout: float = 0.0):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(dropout) if dropout > 0 else None\n",
        "\n",
        "\n",
        "    def forward(self, Q, K, V, mask: Optional[torch.Tensor] = None):\n",
        "        d_k = Q.size(-1)\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(d_k) # (..., seq_q, seq_k)\n",
        "\n",
        "\n",
        "        if mask is not None:\n",
        "            # mask should be broadcastable to scores' shape. We use -1e9 for numerical stability.\n",
        "            scores = scores.masked_fill(mask == 0, float('-1e9'))\n",
        "\n",
        "\n",
        "        attn = F.softmax(scores, dim=-1)\n",
        "        if self.dropout is not None:\n",
        "            attn = self.dropout(attn)\n",
        "        context = torch.matmul(attn, V)\n",
        "        return context, attn"
      ],
      "metadata": {
        "id": "bHZih-S3uFhg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-Head Attention\n"
      ],
      "metadata": {
        "id": "_JC1uQw1zP7B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defines the Multi-Head Attention class, which splits queries, keys, and values into multiple heads, applies scaled dot-product attention to each head, then concatenates and linearly transforms the results to capture information from different representation subspaces."
      ],
      "metadata": {
        "id": "ZtbYR574lCWy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyMultiHeadAttention(nn.Module):\n",
        "    \"\"\"Multi-Head Attention as in the paper.\n",
        "\n",
        "\n",
        "    Splits Q,K,V into h heads, applies scaled dot-product attention, concatenates heads.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    def __init__(self, d_model=512, num_heads=8, dropout=0.1):\n",
        "        super().__init__()\n",
        "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
        "        self.d_model = d_model\n",
        "        self.h = num_heads\n",
        "        self.d_k = d_model // num_heads\n",
        "        self.d_v = self.d_k\n",
        "\n",
        "\n",
        "        # linear projections\n",
        "        self.w_q = nn.Linear(d_model, d_model)\n",
        "        self.w_k = nn.Linear(d_model, d_model)\n",
        "        self.w_v = nn.Linear(d_model, d_model)\n",
        "        self.w_o = nn.Linear(d_model, d_model)\n",
        "\n",
        "\n",
        "        self.attention = ScaledDotProductAttention(dropout=dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, query, key, value, mask: Optional[torch.Tensor] = None):\n",
        "        # query/key/value: (batch, seq_len, d_model)\n",
        "        B = query.size(0)\n",
        "\n",
        "\n",
        "        # linear projections\n",
        "        Q = self.w_q(query) # (B, seq_q, d_model)\n",
        "        K = self.w_k(key)\n",
        "        V = self.w_v(value)\n",
        "\n",
        "\n",
        "        # split into heads\n",
        "        Q = Q.view(B, -1, self.h, self.d_k).transpose(1, 2) # (B, h, seq_q, d_k)\n",
        "        K = K.view(B, -1, self.h, self.d_k).transpose(1, 2) # (B, h, seq_k, d_k)\n",
        "        V = V.view(B, -1, self.h, self.d_k).transpose(1, 2) # (B, h, seq_v, d_v)\n",
        "\n",
        "\n",
        "        # adjust mask for heads if provided: expected mask shape -> (B, 1, seq_q, seq_k) or broadcastable\n",
        "        if mask is not None:\n",
        "            # ensure mask shape is (B, 1, seq_q, seq_k)\n",
        "            mask = mask.unsqueeze(1) if mask.dim() == 3 else mask\n",
        "\n",
        "\n",
        "        # apply attention on all the projected vectors in batch\n",
        "        context, attn = self.attention(Q, K, V, mask=mask) # context: (B, h, seq_q, d_v)\n",
        "\n",
        "\n",
        "        # concat heads\n",
        "        context = context.transpose(1, 2).contiguous().view(B, -1, self.h * self.d_k) # (B, seq_q, d_model)\n",
        "\n",
        "\n",
        "        output = self.w_o(context)\n",
        "        output = self.dropout(output)\n",
        "        return output, attn"
      ],
      "metadata": {
        "id": "wcPKfOvpwNnN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Position-wise Feed-Forward Network\n"
      ],
      "metadata": {
        "id": "beKi2LpozKYk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defines the Position-wise Feed-Forward Network, which applies two linear layers with a ReLU activation and dropout in between to process each position independently in the sequence."
      ],
      "metadata": {
        "id": "nR5FqTKhlH1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyPositionwiseFFN(nn.Module):\n",
        "    \"\"\"Two-layer feed-forward network with ReLU activation in between.\"\"\"\n",
        "\n",
        "\n",
        "    def __init__(self, d_model=512, d_ff=2048, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(d_model, d_ff)\n",
        "        self.linear2 = nn.Linear(d_ff, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear2(self.dropout(F.relu(self.linear1(x))))"
      ],
      "metadata": {
        "id": "D-9DfP4swbBX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Positional Encoding"
      ],
      "metadata": {
        "id": "fN73e8GA2ADz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defines the Positional Encoding class, which adds fixed sinusoidal position information to input embeddings so the model can understand the order of tokens in a sequence."
      ],
      "metadata": {
        "id": "LQYK7TK1lN5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyPositionalEncoding(nn.Module):\n",
        "    \"\"\"Fixed sinusoidal positional encoding as in the paper.\"\"\"\n",
        "\n",
        "\n",
        "    def __init__(self, d_model=512, max_len=5000, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0) # (1, max_len, d_model)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, seq_len, d_model)\n",
        "        x = x + self.pe[:, : x.size(1), :]\n",
        "        return self.dropout(x)"
      ],
      "metadata": {
        "id": "GbCkZ-dmzHzE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoder Layer"
      ],
      "metadata": {
        "id": "YgrLLcq93QWs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defines the Encoder Layer, which performs self-attention followed by a feed-forward network, using residual connections, dropout, and layer normalization to stabilize training and improve performance."
      ],
      "metadata": {
        "id": "-HjSc7BplUHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyEncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model=512, num_heads=8, d_ff=2048, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.self_attn = MyMultiHeadAttention(d_model=d_model, num_heads=num_heads, dropout=dropout)\n",
        "        self.ffn = MyPositionwiseFFN(d_model=d_model, d_ff=d_ff, dropout=dropout)\n",
        "        self.norm1 = nn.LayerNorm(d_model, eps=1e-6)\n",
        "        self.norm2 = nn.LayerNorm(d_model, eps=1e-6)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x, src_mask: Optional[torch.Tensor] = None):\n",
        "        # Self-attention sublayer\n",
        "        attn_output, _ = self.self_attn(x, x, x, mask=src_mask)\n",
        "        x = self.norm1(x + self.dropout(attn_output)) # residual + layernorm\n",
        "\n",
        "\n",
        "        # Feed-forward sublayer\n",
        "        ffn_output = self.ffn(x)\n",
        "        x = self.norm2(x + self.dropout(ffn_output))\n",
        "        return x"
      ],
      "metadata": {
        "id": "zUdtZyhc2CON"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decoder Layer"
      ],
      "metadata": {
        "id": "rQXnLy-33giW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defines the Decoder Layer, which performs masked self-attention, encoder-decoder (cross) attention, and a feed-forward network—each followed by residual connections, dropout, and layer normalization to maintain stable learning."
      ],
      "metadata": {
        "id": "QTieP3gVlY9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model=512, num_heads=8, d_ff=2048, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.self_attn = MyMultiHeadAttention(d_model=d_model, num_heads=num_heads, dropout=dropout)\n",
        "        self.cross_attn = MyMultiHeadAttention(d_model=d_model, num_heads=num_heads, dropout=dropout)\n",
        "        self.ffn = MyPositionwiseFFN(d_model=d_model, d_ff=d_ff, dropout=dropout)\n",
        "        self.norm1 = nn.LayerNorm(d_model, eps=1e-6)\n",
        "        self.norm2 = nn.LayerNorm(d_model, eps=1e-6)\n",
        "        self.norm3 = nn.LayerNorm(d_model, eps=1e-6)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x, enc_output, tgt_mask: Optional[torch.Tensor] = None, memory_mask: Optional[torch.Tensor] = None):\n",
        "        # Masked self-attention\n",
        "        self_attn_output, _ = self.self_attn(x, x, x, mask=tgt_mask)\n",
        "        x = self.norm1(x + self.dropout(self_attn_output))\n",
        "\n",
        "\n",
        "        # Cross-attention (encoder-decoder attention)\n",
        "        cross_attn_output, cross_attn_weights = self.cross_attn(x, enc_output, enc_output, mask=memory_mask)\n",
        "        x = self.norm2(x + self.dropout(cross_attn_output))\n",
        "\n",
        "\n",
        "        # Feed-forward\n",
        "        ffn_output = self.ffn(x)\n",
        "        x = self.norm3(x + self.dropout(ffn_output))\n",
        "        return x, cross_attn_weights"
      ],
      "metadata": {
        "id": "ySx_bizo3SFN"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoder (stack of N layers)"
      ],
      "metadata": {
        "id": "r0lXuZqN330w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defines the Encoder, which stacks multiple encoder layers to process the input sequence and extract rich contextual representations."
      ],
      "metadata": {
        "id": "zHME8W5EleAT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyEncoder(nn.Module):\n",
        "    def __init__(self, num_layers=6, d_model=512, num_heads=8, d_ff=2048, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([\n",
        "            MyEncoderLayer(d_model=d_model, num_heads=num_heads, d_ff=d_ff, dropout=dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "\n",
        "    def forward(self, src, src_mask: Optional[torch.Tensor] = None):\n",
        "        x = src\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, src_mask=src_mask)\n",
        "        return x"
      ],
      "metadata": {
        "id": "QZb0tzJN3iLG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decoder (stack of N layers)"
      ],
      "metadata": {
        "id": "jCsxAuqX4UBl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defines the Decoder, which stacks multiple decoder layers to generate the output sequence by attending to both previous target tokens and the encoder’s output."
      ],
      "metadata": {
        "id": "lHs5H2g0ljCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDecoder(nn.Module):\n",
        "    def __init__(self, num_layers=6, d_model=512, num_heads=8, d_ff=2048, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([\n",
        "            MyDecoderLayer(d_model=d_model, num_heads=num_heads, d_ff=d_ff, dropout=dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "\n",
        "    def forward(self, tgt, enc_output, tgt_mask: Optional[torch.Tensor] = None, memory_mask: Optional[torch.Tensor] = None):\n",
        "        x = tgt\n",
        "        all_cross_attns = []\n",
        "        for layer in self.layers:\n",
        "            x, cross_attn = layer(x, enc_output, tgt_mask=tgt_mask, memory_mask=memory_mask)\n",
        "            all_cross_attns.append(cross_attn)\n",
        "        return x, all_cross_attns"
      ],
      "metadata": {
        "id": "JadOeq6i35j-"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Full Transformer"
      ],
      "metadata": {
        "id": "bg_yJpS24rE-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defines the full Transformer model, including token embeddings, positional encoding, stacked encoder and decoder, and a final linear layer to project decoder outputs to the target vocabulary."
      ],
      "metadata": {
        "id": "E6UKu_rbloGE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyTransformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        src_vocab_size: int,\n",
        "        tgt_vocab_size: int,\n",
        "        d_model: int = 512,\n",
        "        num_heads: int = 8,\n",
        "        d_ff: int = 2048,\n",
        "        num_layers: int = 6,\n",
        "        max_seq_len: int = 512,\n",
        "        dropout: float = 0.1,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.src_tok_emb = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.tgt_tok_emb = nn.Embedding(tgt_vocab_size, d_model)\n",
        "        self.pos_enc = MyPositionalEncoding(d_model=d_model, max_len=max_seq_len, dropout=dropout)\n",
        "\n",
        "\n",
        "        self.encoder = MyEncoder(num_layers=num_layers, d_model=d_model, num_heads=num_heads, d_ff=d_ff, dropout=dropout)\n",
        "        self.decoder = MyDecoder(num_layers=num_layers, d_model=d_model, num_heads=num_heads, d_ff=d_ff, dropout=dropout)\n",
        "\n",
        "\n",
        "        self.out_proj = nn.Linear(d_model, tgt_vocab_size)\n",
        "\n",
        "\n",
        "        # initialize parameters as in the paper (xavier)\n",
        "        self._init_parameters()\n",
        "\n",
        "\n",
        "    def _init_parameters(self):\n",
        "        for p in self.parameters():\n",
        "            if p.dim() > 1:\n",
        "                nn.init.xavier_uniform_(p)\n",
        "\n",
        "\n",
        "    def forward(self, src_input, tgt_input, src_mask: Optional[torch.Tensor] = None, tgt_mask: Optional[torch.Tensor] = None, memory_mask: Optional[torch.Tensor] = None):\n",
        "        # src_input, tgt_input: (B, seq_len) -- token ids\n",
        "        src_emb = self.src_tok_emb(src_input) * math.sqrt(self.d_model)\n",
        "        tgt_emb = self.tgt_tok_emb(tgt_input) * math.sqrt(self.d_model)\n",
        "\n",
        "\n",
        "        src_emb = self.pos_enc(src_emb)\n",
        "        tgt_emb = self.pos_enc(tgt_emb)\n",
        "\n",
        "\n",
        "        enc_output = self.encoder(src_emb, src_mask)\n",
        "        dec_output, cross_attns = self.decoder(tgt_emb, enc_output, tgt_mask=tgt_mask, memory_mask=memory_mask)\n",
        "\n",
        "\n",
        "        logits = self.out_proj(dec_output) # (B, seq_len_tgt, tgt_vocab_size)\n",
        "        return logits, cross_attns"
      ],
      "metadata": {
        "id": "gMhQKWdi4V5J"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mask helpers"
      ],
      "metadata": {
        "id": "DploIySl5PqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provides functions to create attention masks:\n",
        "\n",
        "- create_padding_mask hides padding tokens,\n",
        "\n",
        "- create_look_ahead_mask prevents attention to future tokens,\n",
        "\n",
        "- combine_masks merges padding and look-ahead masks for decoder attention."
      ],
      "metadata": {
        "id": "Ju0FZtdQlu7R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_padding_mask(seq, pad_token=0):\n",
        "    \"\"\"Create a mask to hide padding tokens.\n",
        "\n",
        "\n",
        "    Returns a mask of shape (batch, 1, 1, seq_len) with 0 for real tokens and 1 for PADs.\n",
        "    But our attention expects mask with 1 for allowed? In this implementation ScaledDotProductAttention\n",
        "    masks positions where mask == 0; so we return mask where PAD positions are 0 and others are 1.\n",
        "\n",
        "\n",
        "    To be consistent, we produce a mask with 1 for allowed positions and 0 for PADs, and later in\n",
        "    ScaledDotProductAttention we invert with masked_fill(mask == 0, -inf).\n",
        "    \"\"\"\n",
        "    # seq: (B, seq_len)\n",
        "    mask = (seq != pad_token).unsqueeze(1).unsqueeze(2).to(seq.device) # (B,1,1,seq_len)\n",
        "    # For broadcasting into (B, h, seq_q, seq_k) or (B, seq_q, seq_k)\n",
        "    return mask\n",
        "\n",
        "\n",
        "\n",
        "def create_look_ahead_mask(size):\n",
        "    \"\"\"Mask out future positions. Returns (1, size, size) or (size, size) mask with 1s in allowed positions.\"\"\"\n",
        "    mask = torch.triu(torch.ones((size, size), dtype=torch.bool), diagonal=1) # upper triangular\n",
        "    # allowed positions should be True, so invert\n",
        "    return (~mask).unsqueeze(0) # (1, size, size)\n",
        "\n",
        "\n",
        "\n",
        "def combine_masks(pad_mask_src=None, pad_mask_tgt=None, look_ahead_mask=None):\n",
        "    \"\"\"Combine padding and look-ahead masks into the shape expected by attention.\n",
        "\n",
        "\n",
        "    Typical uses:\n",
        "    - src_mask for encoder self-attn: pad_mask_src -> (B,1,1,seq_len_src)\n",
        "    - tgt_mask for decoder self-attn: combined pad_mask_tgt & look_ahead -> (B,1,seq_len_tgt,seq_len_tgt)\n",
        "    - memory_mask for cross-attn: pad_mask_src broadcasted -> (B,1,1,seq_len_src) or (B,1,seq_len_tgt,seq_len_src)\n",
        "    \"\"\"\n",
        "    if pad_mask_tgt is not None and look_ahead_mask is not None:\n",
        "        # pad_mask_tgt: (B,1,1,seq_len_tgt), look_ahead_mask: (1, seq_len_tgt, seq_len_tgt)\n",
        "        # We want result shape (B, 1, seq_len_tgt, seq_len_tgt)\n",
        "        B = pad_mask_tgt.size(0)\n",
        "        seq_len = pad_mask_tgt.size(-1)\n",
        "        # squeeze pad to (B, seq_len)\n",
        "        pad = pad_mask_tgt.squeeze(1).squeeze(1).unsqueeze(2) # (B, seq_len, 1)\n",
        "        look = look_ahead_mask.to(pad_mask_tgt.device).expand(B, -1, -1) # (B, seq_len, seq_len)\n",
        "        combined = pad & look # (B, seq_len, seq_len)\n",
        "        return combined.unsqueeze(1) # (B,1,seq_len,seq_len)\n",
        "\n",
        "\n",
        "    return None"
      ],
      "metadata": {
        "id": "3fYXkf444uiY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization function\n"
      ],
      "metadata": {
        "id": "d8HRjEE20O0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_attention(attn, head=0):\n",
        "    # attn: (B, h, seq_q, seq_k)\n",
        "    attn_matrix = attn[0, head].detach().cpu().numpy() # first batch, selected head\n",
        "    plt.figure(figsize=(6,6))\n",
        "    plt.imshow(attn_matrix, cmap='viridis')\n",
        "    plt.title(f'Attention Heatmap - Head {head}')\n",
        "    plt.xlabel('Key Position')\n",
        "    plt.ylabel('Query Position')\n",
        "    plt.colorbar()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "k-Y1o5AB0M7e"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Minimal smoke-test / example usage"
      ],
      "metadata": {
        "id": "cPoAZFX45iNp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Runs a test script that creates a dummy Transformer model, generates sample input sequences with padding, builds attention masks, performs a forward pass, and prints the shapes to verify the model works correctly."
      ],
      "metadata": {
        "id": "v5dN9Cm7l3FR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    # Base model hyperparameters\n",
        "    d_model = 512\n",
        "    num_heads = 8\n",
        "    d_ff = 2048\n",
        "    num_layers = 6\n",
        "    dropout = 0.1\n",
        "\n",
        "\n",
        "    # Dummy vocabulary sizes (small for the test)\n",
        "    src_vocab_size = 1000\n",
        "    tgt_vocab_size = 1000\n",
        "\n",
        "\n",
        "    # Dummy batch and sequence lengths\n",
        "    B = 2\n",
        "    src_seq_len = 10\n",
        "    tgt_seq_len = 9\n",
        "\n",
        "\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "\n",
        "    # instantiate model\n",
        "    model = MyTransformer(\n",
        "    src_vocab_size=src_vocab_size,\n",
        "    tgt_vocab_size=tgt_vocab_size,\n",
        "    d_model=d_model,\n",
        "    num_heads=num_heads,\n",
        "    d_ff=d_ff,\n",
        "    num_layers=num_layers,\n",
        "    max_seq_len=512,\n",
        "    dropout=dropout,\n",
        "    ).to(device)\n",
        "\n",
        "\n",
        "    # Create dummy input token IDs and masks (0 is PAD token)\n",
        "    src_input = torch.randint(1, src_vocab_size, (B, src_seq_len)).to(device)\n",
        "    tgt_input = torch.randint(1, tgt_vocab_size, (B, tgt_seq_len)).to(device)\n",
        "\n",
        "\n",
        "    # Introduce some PAD tokens for testing padding mask\n",
        "    src_input[0, -2:] = 0\n",
        "    tgt_input[1, -3:] = 0\n",
        "\n",
        "\n",
        "    src_pad_mask = create_padding_mask(src_input, pad_token=0) # (B,1,1,src_seq_len)\n",
        "    tgt_pad_mask = create_padding_mask(tgt_input, pad_token=0) # (B,1,1,tgt_seq_len)\n",
        "\n",
        "\n",
        "    look_ahead = create_look_ahead_mask(tgt_seq_len) # (1, tgt_seq_len, tgt_seq_len)\n",
        "    tgt_mask = combine_masks(pad_mask_src=None, pad_mask_tgt=tgt_pad_mask, look_ahead_mask=look_ahead) # (B,1,tgt_seq_len,tgt_seq_len)\n",
        "\n",
        "\n",
        "    # memory mask shapes need to match (B,1,1,src_seq_len) or (B,1,tgt_seq_len,src_seq_len); here we expand pad\n",
        "    memory_mask = src_pad_mask.unsqueeze(2) if src_pad_mask.dim() == 4 else src_pad_mask\n",
        "\n",
        "\n",
        "    print('src_input shape:', src_input.shape)\n",
        "    print('tgt_input shape:', tgt_input.shape)\n",
        "    print('src_pad_mask shape:', src_pad_mask.shape)\n",
        "    print('tgt_mask shape:', tgt_mask.shape)\n",
        "\n",
        "\n",
        "    logits, cross_attns = model(src_input, tgt_input, src_mask=src_pad_mask.squeeze(2).squeeze(2), tgt_mask=tgt_mask, memory_mask=src_pad_mask)\n",
        "    # NOTE: In our MyMultiHeadAttention we accept mask shapes that are broadcastable. For clarity we passed\n",
        "    # different shapes; the attention code will attempt to expand/broadcast.\n",
        "\n",
        "\n",
        "    print('logits shape:', logits.shape) # expected (B, tgt_seq_len, tgt_vocab_size)\n",
        "\n",
        "\n",
        "    # Quick assertions\n",
        "    assert logits.shape == (B, tgt_seq_len, tgt_vocab_size)\n",
        "    print('Successful forward pass with Base Model hyperparameters!')\n",
        "\n",
        "    # Plot attention from the last decoder layer, first head\n",
        "    if cross_attns:\n",
        "        print(f'Plotting cross-attention from the last decoder layer (layer {len(cross_attns)-1}, head 0)')\n",
        "        plot_attention(cross_attns[-1], head=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "id": "Kw9YLnZU5RSW",
        "outputId": "68ceee0a-8834-4c44-d7d3-4b28d52a43a7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_input shape: torch.Size([2, 10])\n",
            "tgt_input shape: torch.Size([2, 9])\n",
            "src_pad_mask shape: torch.Size([2, 1, 1, 10])\n",
            "tgt_mask shape: torch.Size([2, 1, 9, 9])\n",
            "logits shape: torch.Size([2, 9, 1000])\n",
            "Successful forward pass with Base Model hyperparameters!\n",
            "Plotting cross-attention from the last decoder layer (layer 5, head 0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Afbdz3mc5m41"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}