{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83b10694",
   "metadata": {},
   "source": [
    "\n",
    "# Practical 1: Text Preprocessing   \n",
    "\n",
    "This practical covers the **fundamental concepts and implementation** of text preprocessing for Natural Language Processing (NLP). Preprocessing transforms raw text into a clean, structured format that is suitable for machine learning algorithms.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad46fa0",
   "metadata": {},
   "source": [
    "\n",
    "## Primary Aim  \n",
    "**To build a robust, reusable text preprocessing pipeline for downstream NLP tasks.**\n",
    "\n",
    "---\n",
    "\n",
    "## Specific Objectives  \n",
    "- Prepare clean text data for **classification tasks** (sentiment analysis, spam detection, etc.)  \n",
    "- Improve text quality for **information retrieval** (search engines, recommendation systems)  \n",
    "- Preprocess corpora for **topic modeling** (LDA, NMF)  \n",
    "- Perform **feature engineering** with numerical text representations  \n",
    "- Enhance **data quality** by removing noise and inconsistencies  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfed34ce",
   "metadata": {},
   "source": [
    "\n",
    "## Module Info  \n",
    "- **Unit**: 3  \n",
    "- **Learning Outcome**: Implement common text preprocessing techniques  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cb6e69",
   "metadata": {},
   "source": [
    "\n",
    "## Section 0: Creating Data Sets  \n",
    "\n",
    "### ðŸ”¹ Theory Notes  \n",
    "Before applying preprocessing techniques, we create a sample dataset. In practice, text data may come from sources like social media posts, reviews, or web scraping.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f226cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When life gives you lemons, make lemonade! ðŸ™‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>She bought 2 lemons for $1 at Maven Market.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A dozen lemons will make a gallon of lemonade. [AllRecipes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lemon, lemon, lemons, lemon, lemon, lemons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He's running to the market to get a lemon - there's a great sale today.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Does Maven Market carry Eureka lemons or Meyer lemons?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>An Arnold Palmer is half lemonade, half iced tea. [Wikipedia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>iced tea is my favorite</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  sentence\n",
       "0                             When life gives you lemons, make lemonade! ðŸ™‚\n",
       "1                              She bought 2 lemons for $1 at Maven Market.\n",
       "2              A dozen lemons will make a gallon of lemonade. [AllRecipes]\n",
       "3                               lemon, lemon, lemons, lemon, lemon, lemons\n",
       "4  He's running to the market to get a lemon - there's a great sale today.\n",
       "5                   Does Maven Market carry Eureka lemons or Meyer lemons?\n",
       "6            An Arnold Palmer is half lemonade, half iced tea. [Wikipedia]\n",
       "7                                                  iced tea is my favorite"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import pandas for data manipulation\n",
    "import pandas as pd\n",
    "data = [\n",
    "    # Sample sentences with various text challenges\n",
    "    'When life gives you lemons, make lemonade! ðŸ™‚',\n",
    "    'She bought 2 lemons for $1 at Maven Market.',\n",
    "    'A dozen lemons will make a gallon of lemonade. [AllRecipes]',\n",
    "    'lemon, lemon, lemons, lemon, lemon, lemons',\n",
    "    # Example with dash and contraction\n",
    "    \"He's running to the market to get a lemon - there's a great sale today.\",\n",
    "    'Does Maven Market carry Eureka lemons or Meyer lemons?',\n",
    "    'An Arnold Palmer is half lemonade, half iced tea. [Wikipedia]',\n",
    "    'iced tea is my favorite'\n",
    " ]\n",
    "# Convert list to DataFrame for easier manipulation\n",
    "data_df = pd.DataFrame(data, columns=['sentence'])\n",
    "# Set display option to show full text content\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "# Display the DataFrame\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c45756",
   "metadata": {},
   "source": [
    "## Section 1: Preprocessing\n",
    "### 1.1 Normalization\n",
    "Convert all text to lowercase for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5643cd2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>clean_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When life gives you lemons, make lemonade! ðŸ™‚</td>\n",
       "      <td>when life gives you lemons, make lemonade! ðŸ™‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>She bought 2 lemons for $1 at Maven Market.</td>\n",
       "      <td>she bought 2 lemons for $1 at maven market.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A dozen lemons will make a gallon of lemonade. [AllRecipes]</td>\n",
       "      <td>a dozen lemons will make a gallon of lemonade. [allrecipes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lemon, lemon, lemons, lemon, lemon, lemons</td>\n",
       "      <td>lemon, lemon, lemons, lemon, lemon, lemons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He's running to the market to get a lemon - there's a great sale today.</td>\n",
       "      <td>he's running to the market to get a lemon - there's a great sale today.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Does Maven Market carry Eureka lemons or Meyer lemons?</td>\n",
       "      <td>does maven market carry eureka lemons or meyer lemons?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>An Arnold Palmer is half lemonade, half iced tea. [Wikipedia]</td>\n",
       "      <td>an arnold palmer is half lemonade, half iced tea. [wikipedia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>iced tea is my favorite</td>\n",
       "      <td>iced tea is my favorite</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  sentence  \\\n",
       "0                             When life gives you lemons, make lemonade! ðŸ™‚   \n",
       "1                              She bought 2 lemons for $1 at Maven Market.   \n",
       "2              A dozen lemons will make a gallon of lemonade. [AllRecipes]   \n",
       "3                               lemon, lemon, lemons, lemon, lemon, lemons   \n",
       "4  He's running to the market to get a lemon - there's a great sale today.   \n",
       "5                   Does Maven Market carry Eureka lemons or Meyer lemons?   \n",
       "6            An Arnold Palmer is half lemonade, half iced tea. [Wikipedia]   \n",
       "7                                                  iced tea is my favorite   \n",
       "\n",
       "                                                            clean_sentence  \n",
       "0                             when life gives you lemons, make lemonade! ðŸ™‚  \n",
       "1                              she bought 2 lemons for $1 at maven market.  \n",
       "2              a dozen lemons will make a gallon of lemonade. [allrecipes]  \n",
       "3                               lemon, lemon, lemons, lemon, lemon, lemons  \n",
       "4  he's running to the market to get a lemon - there's a great sale today.  \n",
       "5                   does maven market carry eureka lemons or meyer lemons?  \n",
       "6            an arnold palmer is half lemonade, half iced tea. [wikipedia]  \n",
       "7                                                  iced tea is my favorite  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a copy of the original DataFrame to preserve raw data\n",
    "spacy_df = data_df.copy()\n",
    "# Convert all sentences to lowercase for normalization\n",
    "spacy_df['clean_sentence'] = spacy_df['sentence'].str.lower()\n",
    "# Show both original and normalized sentences\n",
    "spacy_df[['sentence', 'clean_sentence']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f1a893",
   "metadata": {},
   "source": [
    "### 1.2 Text Cleaning\n",
    "Remove citations, URLs, emails, social media handles, and non-alphanumeric characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32531f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>clean_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When life gives you lemons, make lemonade! ðŸ™‚</td>\n",
       "      <td>when life gives you lemons make lemonade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>She bought 2 lemons for $1 at Maven Market.</td>\n",
       "      <td>she bought 2 lemons for 1 at maven market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A dozen lemons will make a gallon of lemonade. [AllRecipes]</td>\n",
       "      <td>a dozen lemons will make a gallon of lemonade allrecipes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lemon, lemon, lemons, lemon, lemon, lemons</td>\n",
       "      <td>lemon lemon lemons lemon lemon lemons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He's running to the market to get a lemon - there's a great sale today.</td>\n",
       "      <td>he s running to the market to get a lemon there s a great sale today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Does Maven Market carry Eureka lemons or Meyer lemons?</td>\n",
       "      <td>does maven market carry eureka lemons or meyer lemons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>An Arnold Palmer is half lemonade, half iced tea. [Wikipedia]</td>\n",
       "      <td>an arnold palmer is half lemonade half iced tea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>iced tea is my favorite</td>\n",
       "      <td>iced tea is my favorite</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  sentence  \\\n",
       "0                             When life gives you lemons, make lemonade! ðŸ™‚   \n",
       "1                              She bought 2 lemons for $1 at Maven Market.   \n",
       "2              A dozen lemons will make a gallon of lemonade. [AllRecipes]   \n",
       "3                               lemon, lemon, lemons, lemon, lemon, lemons   \n",
       "4  He's running to the market to get a lemon - there's a great sale today.   \n",
       "5                   Does Maven Market carry Eureka lemons or Meyer lemons?   \n",
       "6            An Arnold Palmer is half lemonade, half iced tea. [Wikipedia]   \n",
       "7                                                  iced tea is my favorite   \n",
       "\n",
       "                                                         clean_sentence  \n",
       "0                              when life gives you lemons make lemonade  \n",
       "1                             she bought 2 lemons for 1 at maven market  \n",
       "2              a dozen lemons will make a gallon of lemonade allrecipes  \n",
       "3                                 lemon lemon lemons lemon lemon lemons  \n",
       "4  he s running to the market to get a lemon there s a great sale today  \n",
       "5                 does maven market carry eureka lemons or meyer lemons  \n",
       "6                       an arnold palmer is half lemonade half iced tea  \n",
       "7                                               iced tea is my favorite  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove specific citations like [wikipedia] from text\n",
    "spacy_df['clean_sentence'] = spacy_df['clean_sentence'].str.replace('[wikipedia]', '', regex=False)\n",
    "# Define regex pattern for advanced cleaning (URLs, emails, non-alphanumeric, etc.)\n",
    "combined = r'https?://\\\\S+|www\\\\.\\\\S+|<.*?>|\\\\S+@\\\\S+\\\\.\\\\S+|@\\\\w+|#\\\\w+|[^A-Za-z0-9\\\\s]'\n",
    "# Apply regex to clean unwanted patterns\n",
    "spacy_df['clean_sentence'] = spacy_df['clean_sentence'].str.replace(combined, ' ', regex=True)\n",
    "# Normalize whitespace (replace multiple spaces with single space) and strip leading/trailing spaces\n",
    "spacy_df['clean_sentence'] = spacy_df['clean_sentence'].str.replace(r'\\\\s+', ' ', regex=True).str.strip()\n",
    "# Show cleaned sentences\n",
    "spacy_df[['sentence', 'clean_sentence']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbec2768",
   "metadata": {},
   "source": [
    "## Section 1.2: Advanced Text Processing with spaCy\n",
    "Install and load spaCy's English model, then process a sample sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961f07e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['when', 'life', 'gives', 'you', 'lemons', 'make', 'lemonade']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import spaCy for advanced NLP processing\n",
    "import spacy\n",
    "# If not already installed, uncomment the next line to download the English model\n",
    "# !python -m spacy download en_core_web_sm\n",
    "# Load the pre-trained English language model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "# Select a sample cleaned sentence for processing\n",
    "phrase = spacy_df.clean_sentence[0]\n",
    "# Process the sentence with spaCy\n",
    "doc = nlp(phrase)\n",
    "# Display tokens extracted from the sentence\n",
    "[token.text for token in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb07dc9",
   "metadata": {},
   "source": [
    "### Lemmatization\n",
    "Reduce words to their base form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ac7172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['when', 'life', 'give', 'you', 'lemon', 'make', 'lemonade']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract lemmatized (base) forms of each token in the sentence\n",
    "[token.lemma_ for token in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba5f4af",
   "metadata": {},
   "source": [
    "### Stop Words Removal\n",
    "Remove common words that carry little meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e2aa8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['life', 'give', 'lemon', 'lemonade']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove stop words and show lemmatized tokens that carry meaning\n",
    "[token.lemma_ for token in doc if not token.is_stop]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12330f4",
   "metadata": {},
   "source": [
    "## Section 2: Creating Reusable Functions\n",
    "Lemmatization and stop word removal in a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45610332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_sentence</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when life gives you lemons make lemonade</td>\n",
       "      <td>life give lemon lemonade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>she bought 2 lemons for 1 at maven market</td>\n",
       "      <td>buy 2 lemon 1 maven market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a dozen lemons will make a gallon of lemonade allrecipes</td>\n",
       "      <td>dozen lemon gallon lemonade allrecipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lemon lemon lemons lemon lemon lemons</td>\n",
       "      <td>lemon lemon lemon lemon lemon lemon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>he s running to the market to get a lemon there s a great sale today</td>\n",
       "      <td>s run market lemon s great sale today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>does maven market carry eureka lemons or meyer lemons</td>\n",
       "      <td>maven market carry eureka lemon meyer lemon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>an arnold palmer is half lemonade half iced tea</td>\n",
       "      <td>arnold palmer half lemonade half ice tea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>iced tea is my favorite</td>\n",
       "      <td>ice tea favorite</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         clean_sentence  \\\n",
       "0                              when life gives you lemons make lemonade   \n",
       "1                             she bought 2 lemons for 1 at maven market   \n",
       "2              a dozen lemons will make a gallon of lemonade allrecipes   \n",
       "3                                 lemon lemon lemons lemon lemon lemons   \n",
       "4  he s running to the market to get a lemon there s a great sale today   \n",
       "5                 does maven market carry eureka lemons or meyer lemons   \n",
       "6                       an arnold palmer is half lemonade half iced tea   \n",
       "7                                               iced tea is my favorite   \n",
       "\n",
       "                                     processed  \n",
       "0                     life give lemon lemonade  \n",
       "1                   buy 2 lemon 1 maven market  \n",
       "2        dozen lemon gallon lemonade allrecipe  \n",
       "3          lemon lemon lemon lemon lemon lemon  \n",
       "4        s run market lemon s great sale today  \n",
       "5  maven market carry eureka lemon meyer lemon  \n",
       "6     arnold palmer half lemonade half ice tea  \n",
       "7                             ice tea favorite  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to lemmatize and remove stop words from text\n",
    "def token_lemma_stopw(text):\n",
    "    doc = nlp(text)\n",
    "    output = [token.lemma_ for token in doc if not token.is_stop]\n",
    "    return ' '.join(output)\n",
    "\n",
    "# Apply the function to all cleaned sentences in the DataFrame\n",
    "spacy_df['processed'] = spacy_df['clean_sentence'].apply(token_lemma_stopw)\n",
    "# Show cleaned and processed sentences\n",
    "spacy_df[['clean_sentence', 'processed']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d7f1c8",
   "metadata": {},
   "source": [
    "## Section 3: Complete NLP Pipeline\n",
    "Combine all preprocessing steps into a single pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bf82f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                              life give lemon lemonade\n",
       "1                            buy 2 lemon 1 maven market\n",
       "2                 dozen lemon gallon lemonade allrecipe\n",
       "3                   lemon lemon lemon lemon lemon lemon\n",
       "4                 s run market lemon s great sale today\n",
       "5           maven market carry eureka lemon meyer lemon\n",
       "6    arnold palmer half lemonade half ice tea wikipedia\n",
       "7                                      ice tea favorite\n",
       "Name: sentence, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lower_replace(series):\n",
    "    output = series.str.lower()\n",
    "    combined = r'https?://\\\\S+|www\\\\.\\\\S+|<.*?>|\\\\S+@\\\\S+\\\\.\\\\S+|@\\\\w+|#\\\\w+|[^A-Za-z0-9\\\\s]'\n",
    "    output = output.str.replace(combined, ' ', regex=True)\n",
    "    output = output.str.replace(r'\\\\s+', ' ', regex=True).str.strip()\n",
    "    return output\n",
    "\n",
    "# Complete pipeline: normalization, cleaning, lemmatization, stop word removal\n",
    "def nlp_pipeline(series):\n",
    "    output = lower_replace(series)\n",
    "    output = output.apply(token_lemma_stopw)\n",
    "    return output\n",
    "\n",
    "# Apply the pipeline to the original sentences\n",
    "cleaned_text = nlp_pipeline(data_df.sentence)\n",
    "# Display the final processed text\n",
    "cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6048bcf9",
   "metadata": {},
   "source": [
    "## Section 4: Word Representation (Vectorization)\n",
    "Convert processed text into numerical vectors using CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b007073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>allrecipe</th>\n",
       "      <th>arnold</th>\n",
       "      <th>buy</th>\n",
       "      <th>carry</th>\n",
       "      <th>dozen</th>\n",
       "      <th>eureka</th>\n",
       "      <th>favorite</th>\n",
       "      <th>gallon</th>\n",
       "      <th>give</th>\n",
       "      <th>great</th>\n",
       "      <th>...</th>\n",
       "      <th>life</th>\n",
       "      <th>market</th>\n",
       "      <th>maven</th>\n",
       "      <th>meyer</th>\n",
       "      <th>palmer</th>\n",
       "      <th>run</th>\n",
       "      <th>sale</th>\n",
       "      <th>tea</th>\n",
       "      <th>today</th>\n",
       "      <th>wikipedia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   allrecipe  arnold  buy  carry  dozen  eureka  favorite  gallon  give  \\\n",
       "0          0       0    0      0      0       0         0       0     1   \n",
       "1          0       0    1      0      0       0         0       0     0   \n",
       "2          1       0    0      0      1       0         0       1     0   \n",
       "3          0       0    0      0      0       0         0       0     0   \n",
       "4          0       0    0      0      0       0         0       0     0   \n",
       "5          0       0    0      1      0       1         0       0     0   \n",
       "6          0       1    0      0      0       0         0       0     0   \n",
       "7          0       0    0      0      0       0         1       0     0   \n",
       "\n",
       "   great  ...  life  market  maven  meyer  palmer  run  sale  tea  today  \\\n",
       "0      0  ...     1       0      0      0       0    0     0    0      0   \n",
       "1      0  ...     0       1      1      0       0    0     0    0      0   \n",
       "2      0  ...     0       0      0      0       0    0     0    0      0   \n",
       "3      0  ...     0       0      0      0       0    0     0    0      0   \n",
       "4      1  ...     0       1      0      0       0    1     1    0      1   \n",
       "5      0  ...     0       1      1      1       0    0     0    0      0   \n",
       "6      0  ...     0       0      0      0       1    0     0    1      0   \n",
       "7      0  ...     0       0      0      0       0    0     0    1      0   \n",
       "\n",
       "   wikipedia  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "5          0  \n",
       "6          1  \n",
       "7          0  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import CountVectorizer for Bag-of-Words representation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Create a CountVectorizer instance\n",
    "cv = CountVectorizer()\n",
    "# Fit and transform the processed text to get the BoW matrix\n",
    "bow = cv.fit_transform(cleaned_text)\n",
    "# Convert the matrix to a DataFrame for easy viewing\n",
    "pd.DataFrame(bow.toarray(), columns=cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b66ce9e",
   "metadata": {},
   "source": [
    "### Advanced Count Vectorization\n",
    "Filter out stop words and rare words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b77ce1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ice          2\n",
       "lemon       12\n",
       "lemonade     3\n",
       "market       3\n",
       "maven        2\n",
       "tea          2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Advanced CountVectorizer: remove stop words, use unigrams, filter rare words\n",
    "cv1 = CountVectorizer(stop_words='english', ngram_range=(1,1), min_df=2)\n",
    "# Fit and transform the processed text\n",
    "bow1 = cv1.fit_transform(cleaned_text)\n",
    "# Convert to DataFrame for analysis\n",
    "bow1_df = pd.DataFrame(bow1.toarray(), columns=cv1.get_feature_names_out())\n",
    "# Calculate term frequencies across all documents\n",
    "term_freq = bow1_df.sum()\n",
    "# Display term frequencies\n",
    "term_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea99cdd",
   "metadata": {},
   "source": [
    "## Section 5: TF-IDF (Term Frequency-Inverse Document Frequency)\n",
    "Calculate TF-IDF scores for better feature weighting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6321f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>allrecipe</th>\n",
       "      <th>arnold</th>\n",
       "      <th>buy</th>\n",
       "      <th>carry</th>\n",
       "      <th>dozen</th>\n",
       "      <th>eureka</th>\n",
       "      <th>favorite</th>\n",
       "      <th>gallon</th>\n",
       "      <th>give</th>\n",
       "      <th>great</th>\n",
       "      <th>...</th>\n",
       "      <th>life</th>\n",
       "      <th>market</th>\n",
       "      <th>maven</th>\n",
       "      <th>meyer</th>\n",
       "      <th>palmer</th>\n",
       "      <th>run</th>\n",
       "      <th>sale</th>\n",
       "      <th>tea</th>\n",
       "      <th>today</th>\n",
       "      <th>wikipedia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600547</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600547</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.63563</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.459683</td>\n",
       "      <td>0.532707</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.514841</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.514841</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.514841</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.457738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.331033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.457738</td>\n",
       "      <td>0.457738</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.457738</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.437511</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.437511</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.316405</td>\n",
       "      <td>0.366668</td>\n",
       "      <td>0.437511</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.334679</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.334679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.280487</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.334679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.644859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.540443</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   allrecipe    arnold      buy     carry     dozen    eureka  favorite  \\\n",
       "0   0.000000  0.000000  0.00000  0.000000  0.000000  0.000000  0.000000   \n",
       "1   0.000000  0.000000  0.63563  0.000000  0.000000  0.000000  0.000000   \n",
       "2   0.514841  0.000000  0.00000  0.000000  0.514841  0.000000  0.000000   \n",
       "3   0.000000  0.000000  0.00000  0.000000  0.000000  0.000000  0.000000   \n",
       "4   0.000000  0.000000  0.00000  0.000000  0.000000  0.000000  0.000000   \n",
       "5   0.000000  0.000000  0.00000  0.437511  0.000000  0.437511  0.000000   \n",
       "6   0.000000  0.334679  0.00000  0.000000  0.000000  0.000000  0.000000   \n",
       "7   0.000000  0.000000  0.00000  0.000000  0.000000  0.000000  0.644859   \n",
       "\n",
       "     gallon      give     great  ...      life    market     maven     meyer  \\\n",
       "0  0.000000  0.600547  0.000000  ...  0.600547  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  ...  0.000000  0.459683  0.532707  0.000000   \n",
       "2  0.514841  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.457738  ...  0.000000  0.331033  0.000000  0.000000   \n",
       "5  0.000000  0.000000  0.000000  ...  0.000000  0.316405  0.366668  0.437511   \n",
       "6  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "7  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "     palmer       run      sale       tea     today  wikipedia  \n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000  \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000  \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000  \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000  \n",
       "4  0.000000  0.457738  0.457738  0.000000  0.457738   0.000000  \n",
       "5  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000  \n",
       "6  0.334679  0.000000  0.000000  0.280487  0.000000   0.334679  \n",
       "7  0.000000  0.000000  0.000000  0.540443  0.000000   0.000000  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import TfidfVectorizer for TF-IDF representation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Create a TfidfVectorizer instance\n",
    "tv = TfidfVectorizer()\n",
    "# Fit and transform the processed text to get the TF-IDF matrix\n",
    "tvidf = tv.fit_transform(cleaned_text)\n",
    "# Convert the matrix to a DataFrame for easy viewing\n",
    "tvidf_df = pd.DataFrame(tvidf.toarray(), columns=tv.get_feature_names_out())\n",
    "# Display the TF-IDF DataFrame\n",
    "tvidf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19783c4",
   "metadata": {},
   "source": [
    "### TF-IDF with Filtering\n",
    "Focus on words that appear in at least 2 documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d842f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ice</th>\n",
       "      <th>lemon</th>\n",
       "      <th>lemonade</th>\n",
       "      <th>market</th>\n",
       "      <th>maven</th>\n",
       "      <th>tea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.568471</td>\n",
       "      <td>0.822704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.411442</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.595449</td>\n",
       "      <td>0.690041</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.568471</td>\n",
       "      <td>0.822704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.568471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.822704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.670130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.484914</td>\n",
       "      <td>0.561947</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.603613</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.520868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.603613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ice     lemon  lemonade    market     maven       tea\n",
       "0  0.000000  0.568471  0.822704  0.000000  0.000000  0.000000\n",
       "1  0.000000  0.411442  0.000000  0.595449  0.690041  0.000000\n",
       "2  0.000000  0.568471  0.822704  0.000000  0.000000  0.000000\n",
       "3  0.000000  1.000000  0.000000  0.000000  0.000000  0.000000\n",
       "4  0.000000  0.568471  0.000000  0.822704  0.000000  0.000000\n",
       "5  0.000000  0.670130  0.000000  0.484914  0.561947  0.000000\n",
       "6  0.603613  0.000000  0.520868  0.000000  0.000000  0.603613\n",
       "7  0.707107  0.000000  0.000000  0.000000  0.000000  0.707107"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF with filtering: only include words appearing in at least 2 documents\n",
    "tv1 = TfidfVectorizer(min_df=2)\n",
    "# Fit and transform the processed text\n",
    "tvidf1 = tv1.fit_transform(cleaned_text)\n",
    "# Convert to DataFrame for analysis\n",
    "tvidf1_df = pd.DataFrame(tvidf1.toarray(), columns=tv1.get_feature_names_out())\n",
    "# Display the filtered TF-IDF DataFrame\n",
    "tvidf1_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93afe095",
   "metadata": {},
   "source": [
    "### N-gram Analysis\n",
    "Include both unigrams and bigrams for phrase-level information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1f02ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lemon                 1.583310\n",
       "lemon lemon           0.857624\n",
       "market                0.767950\n",
       "lemonade              0.743321\n",
       "ice tea               0.625522\n",
       "ice                   0.625522\n",
       "tea                   0.625522\n",
       "maven                 0.621858\n",
       "maven market          0.621858\n",
       "half                  0.505881\n",
       "favorite              0.493436\n",
       "tea favorite          0.493436\n",
       "lemon maven           0.439482\n",
       "buy                   0.439482\n",
       "buy lemon             0.439482\n",
       "give lemon            0.416207\n",
       "life                  0.416207\n",
       "lemon lemonade        0.416207\n",
       "give                  0.416207\n",
       "life give             0.416207\n",
       "gallon lemonade       0.358685\n",
       "dozen lemon           0.358685\n",
       "allrecipe             0.358685\n",
       "dozen                 0.358685\n",
       "gallon                0.358685\n",
       "lemonade allrecipe    0.358685\n",
       "lemon gallon          0.358685\n",
       "sale today            0.319884\n",
       "today                 0.319884\n",
       "great sale            0.319884\n",
       "great                 0.319884\n",
       "market lemon          0.319884\n",
       "lemon great           0.319884\n",
       "run market            0.319884\n",
       "sale                  0.319884\n",
       "run                   0.319884\n",
       "eureka                0.302522\n",
       "meyer lemon           0.302522\n",
       "market carry          0.302522\n",
       "meyer                 0.302522\n",
       "lemon meyer           0.302522\n",
       "carry                 0.302522\n",
       "carry eureka          0.302522\n",
       "eureka lemon          0.302522\n",
       "arnold                0.252941\n",
       "half lemonade         0.252941\n",
       "half ice              0.252941\n",
       "arnold palmer         0.252941\n",
       "lemonade half         0.252941\n",
       "palmer half           0.252941\n",
       "palmer                0.252941\n",
       "tea wikipedia         0.252941\n",
       "wikipedia             0.252941\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# N-gram TF-IDF: include both unigrams and bigrams for phrase-level features\n",
    "tv2 = TfidfVectorizer(ngram_range=(1,2))\n",
    "# Fit and transform the processed text\n",
    "tvidf2 = tv2.fit_transform(cleaned_text)\n",
    "# Convert to DataFrame for analysis\n",
    "tvidf2_df = pd.DataFrame(tvidf2.toarray(), columns=tv2.get_feature_names_out())\n",
    "# Analyze feature importance by summing TF-IDF scores\n",
    "tvidf2_df.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af94c22e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
