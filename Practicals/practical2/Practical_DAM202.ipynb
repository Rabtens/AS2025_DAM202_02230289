{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Practical: Word2Vec Training and Evaluation"
      ],
      "metadata": {
        "id": "s4dB-u-zdi7N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 355,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCFzGT3Ez99w",
        "outputId": "38981dda-5f52-4337-a0cf-6534e6608d9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.listdir(\"/content/drive/MyDrive/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5lbB_nf0wqy",
        "outputId": "a925c01f-6619-49fb-ac49-a987b1ffcb43"
      },
      "execution_count": 356,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Classroom',\n",
              " 'Blank Quiz (1).gform',\n",
              " 'Untitled document (7).gdoc',\n",
              " 'Group5_Trending_YTVideo.zip',\n",
              " 'Colab Notebooks',\n",
              " 'WEB101 PA1.pdf',\n",
              " 'DATA MODEL AND API PRESENTATION.gslides',\n",
              " 'shapes_dataset',\n",
              " 'shape_datasets',\n",
              " 'output (1).csv',\n",
              " '.ipynb_checkpoints',\n",
              " 'attendance_model.h5',\n",
              " 'preprocessed_images',\n",
              " 'preprocessed_images.npy',\n",
              " 'labels.npy',\n",
              " 'shuffled_dataset.csv',\n",
              " 'Untitled presentation.gslides',\n",
              " 'data',\n",
              " '0245c007-d0f7-4eab-be47-a53634fbbf6b.jpeg',\n",
              " 'Untitled document (6).gdoc',\n",
              " 'Untitled document (5).gdoc',\n",
              " 'PORFOLIO.docs.gdoc',\n",
              " 'Blank Quiz.gform',\n",
              " 'Project Recommendation.gdoc',\n",
              " 'Acceptance Letter.gdoc',\n",
              " 'Acceptance Letter.pdf',\n",
              " 'project proposal.gdoc',\n",
              " 'Untitled document (4).gdoc',\n",
              " 'Reference Link.gsheet',\n",
              " 'Daily Report of Internship.gdoc',\n",
              " 'RESUME.pdf',\n",
              " 'Portfolio final',\n",
              " 'linux3.pdf',\n",
              " 'linux 5.pdf',\n",
              " 'marksheet (1).pdf',\n",
              " 'marksheet.pdf',\n",
              " 'Final_ProcurementList_CocoCommercial.gdoc',\n",
              " 'Photogrammetry notes .gdoc',\n",
              " 'DBS_FINAL_PRESENTATION.gslides',\n",
              " 'Internship_Report(2024).docx',\n",
              " 'Reccomendation Letter(Intern).gdoc',\n",
              " 'Kuenzang Rabten.pdf',\n",
              " 'Sprint Report (2).gdoc',\n",
              " 'Sprint Report (1).gdoc',\n",
              " 'Sprint Report (3).gdoc',\n",
              " 'Metrics Summary.gsheet',\n",
              " 'Approvals.gsheet',\n",
              " 'sprint 2.gsheet',\n",
              " 'Metrics Summary sprint 2.gsheet',\n",
              " 'Satellite_Images',\n",
              " 'Sprint 2.gsheet',\n",
              " 'Sprint 2 Doc.gsheet',\n",
              " 'Capstone Final Report.gdoc',\n",
              " 'Intern experience at TTPL.pptx',\n",
              " '2025-02-07 21-59-31.pdf',\n",
              " 'Kuenzang_Rabten_02230389.gdoc',\n",
              " 'Kuenzang_Rabten_02230389.pdf',\n",
              " 'Untitled document (3).gdoc',\n",
              " 'Lab1_Report.gdoc',\n",
              " '02230289.gdoc',\n",
              " 'Untitled document (2).gdoc',\n",
              " 'DIS303_Assignment1.gdoc',\n",
              " '02230289(CTE205_Assignment_1).gdoc',\n",
              " 'Lab_6_02230289.gdoc',\n",
              " 'Lab_7_02230289.gdoc',\n",
              " 'ppt notes.gdoc',\n",
              " 'dso_presentation.gslides',\n",
              " 'C-LOOK Disk Scheduling Algorithm: Efficient Circular Scanning.gslides',\n",
              " 'C-look Scheduling.gslides',\n",
              " '022302891.gsheet',\n",
              " 'Copy .gsheet',\n",
              " '02230289.gsheet',\n",
              " 'Doodleapp_CaseStudy.gdoc',\n",
              " 'Doodleapp_CaseStudy3.gdoc',\n",
              " 'Doodleapp_CaseStudy2.gdoc',\n",
              " 'Untitled document (1).gdoc',\n",
              " 'Question1.gdoc',\n",
              " '(SDA-finals)architecture-characteristics-worksheet.pptx',\n",
              " 'Architecture-worksheet-final.gdoc',\n",
              " 'Architecture Decision Record.gdoc',\n",
              " 'Glossary_domain_term.gdoc',\n",
              " 'Untitled document.gdoc',\n",
              " 'SDA_FINALS_PRESENTATION.gslides',\n",
              " 'Intern experience at TTPL.gslides',\n",
              " 'SWE']"
            ]
          },
          "metadata": {},
          "execution_count": 356
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"/content/drive/MyDrive/SWE/Year3Sem1/DAM_202\", exist_ok=True)"
      ],
      "metadata": {
        "id": "FVJKuPGH1zmk"
      },
      "execution_count": 357,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0. Change Working Directory"
      ],
      "metadata": {
        "id": "gP6aDbkTdtQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ROOT = \"/content/drive/MyDrive/SWE/Year3Sem1/DAM_202\" # Your Working Directory\n",
        "import os\n",
        "os.chdir(ROOT)"
      ],
      "metadata": {
        "id": "fTT7wJHK2Tp9"
      },
      "execution_count": 358,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import os\n",
        "os.listdir()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87KuFTPb2Wwn",
        "outputId": "3805b63e-e71f-45b7-d499-d2a07b025965"
      },
      "execution_count": 359,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['text.txt', 'my_word2vec_model.model']"
            ]
          },
          "metadata": {},
          "execution_count": 359
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word2Vec Training Guide\n",
        "\n",
        "## 1. Introduction\n",
        "\n",
        "### 1.1 Need for Data Feed\n",
        "\n",
        "While pretrained Word2Vec models like Google News are useful, training your own model provides several key advantages:\n",
        "\n",
        "- **Domain Specificity:** Captures terminology unique to your field\n",
        "- **Custom Vocabulary:** Includes words or phrases unique to your dataset\n",
        "- **Full Control:** Allows tuning of hyperparameters and preprocessing\n",
        "- **Privacy:** No reliance on external models for sensitive data\n",
        "- **Learning:** Better understanding of Word2Vec mechanics\n",
        "\n",
        "### 1.2 Word2Vec Neural Network Architecture\n",
        "\n",
        "The Word2Vec model consists of three main layers:\n",
        "\n",
        "- **Input Layer:** One-hot encoded word vectors\n",
        "- **Hidden Layer:** Dense vector representation (word embeddings)\n",
        "- **Output Layer:** Probability distribution over vocabulary\n",
        "\n",
        "### 1.3 CBOW vs Skip-gram\n",
        "\n",
        "| Model | Input → Output | Best for |\n",
        "|-------|----------------|----------|\n",
        "| CBOW | Context words → Center word | Frequent words, syntax |\n",
        "| Skip-gram | Center word → Context words | Rare words, semantics |\n",
        "\n",
        "Key differences:\n",
        "- CBOW is faster and better for syntactic relationships\n",
        "- Skip-gram is slower but captures semantic relationships well\n",
        "\n",
        "## 2. Training Objectives\n",
        "\n",
        "The main goals of Word2Vec training are:\n",
        "\n",
        "- Maximize probability of observed word-context pairs\n",
        "- Minimize probability of random word pairs (negative sampling)\n",
        "- Adjust embeddings to reflect relationships between words\n",
        "\n",
        "### 2.1 Key Training Concepts\n",
        "\n",
        "#### Context Window\n",
        "Number of words considered around the target word:\n",
        "- **Small window (2–3):** Captures syntax\n",
        "- **Large window (5–10):** Captures semantics\n",
        "\n",
        "#### Negative Sampling\n",
        "Speeds up training by sampling a few negative examples instead of computing probabilities for the entire vocabulary.\n",
        "\n",
        "#### Hierarchical Softmax\n",
        "Efficient probability computation using binary tree structure, reducing computational complexity from O(V) to O(log V) where V is vocabulary size."
      ],
      "metadata": {
        "id": "aX6ryMcceHKA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Code Implementation"
      ],
      "metadata": {
        "id": "j22Cf8-6etww"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.1 Data Collection and Preparation"
      ],
      "metadata": {
        "id": "BBrs_rNSeyVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('text.txt', 'r', encoding='utf-8') as f: # Remember your data set path should be specified if not in same working directory\n",
        "    texts = f.readlines()"
      ],
      "metadata": {
        "id": "O36gxIot2ooL"
      },
      "execution_count": 360,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYCgSIG63Sr-",
        "outputId": "6f2397f8-e24f-412d-9bee-77a5cf0c5d1e"
      },
      "execution_count": 361,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"                ALICE'S ADVENTURES IN WONDERLAND\\n\",\n",
              " '\\n',\n",
              " '                          Lewis Carroll\\n',\n",
              " '\\n',\n",
              " '               THE MILLENNIUM FULCRUM EDITION 3.0\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '                            CHAPTER I\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 361
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.2 Data Quality Assessment"
      ],
      "metadata": {
        "id": "EcshhnZUe33I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def assess_data_quality(texts):\n",
        "    \"\"\"Analyze text data quality for Word2Vec training\"\"\"\n",
        "\n",
        "    stats = {\n",
        "        'total_documents': len(texts),\n",
        "        'total_words': 0,\n",
        "        'unique_words': set(),\n",
        "        'sentence_lengths': [],\n",
        "        'word_frequencies': {}\n",
        "    }\n",
        "\n",
        "    for text in texts:\n",
        "        words = text.lower().split()\n",
        "        stats['total_words'] += len(words)\n",
        "        stats['sentence_lengths'].append(len(words))\n",
        "        stats['unique_words'].update(words)\n",
        "\n",
        "        for word in words:\n",
        "            stats['word_frequencies'][word] = stats['word_frequencies'].get(word, 0) + 1\n",
        "\n",
        "    stats['vocabulary_size'] = len(stats['unique_words'])\n",
        "    stats['avg_sentence_length'] = sum(stats['sentence_lengths']) / len(stats['sentence_lengths'])\n",
        "\n",
        "    # Find most common words\n",
        "    sorted_words = sorted(stats['word_frequencies'].items(), key=lambda x: x[1], reverse=True)\n",
        "    stats['top_words'] = sorted_words[:20]\n",
        "\n",
        "    # Quality indicators\n",
        "    stats['quality_score'] = {\n",
        "        'vocabulary_diversity': stats['vocabulary_size'] / stats['total_words'],\n",
        "        'avg_word_frequency': stats['total_words'] / stats['vocabulary_size'],\n",
        "        'rare_words_ratio': sum(1 for count in stats['word_frequencies'].values() if count == 1) / stats['vocabulary_size']\n",
        "    }\n",
        "\n",
        "    return stats\n",
        "\n",
        "# Example usage\n",
        "quality_report = assess_data_quality(texts)\n",
        "print(f\"Total documents: {quality_report['total_documents']:,}\")\n",
        "print(f\"Vocabulary size: {quality_report['vocabulary_size']:,}\")\n",
        "print(f\"Unique Words: {quality_report['unique_words']}\")\n",
        "print(f\"Average sentence length: {quality_report['avg_sentence_length']:.1f}\")\n",
        "print(f\"Vocabulary diversity: {quality_report['quality_score']['vocabulary_diversity']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqxGQ7ha3hzp",
        "outputId": "f16ee805-53ae-462f-bb83-06701e270f63"
      },
      "execution_count": 362,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total documents: 3,598\n",
            "Vocabulary size: 4,950\n",
            "Unique Words: {'footman', 'business,', 'far!\"', 'caterpillar', 'cook,', 'answered', 'worried.', 'unhappy', 'for,', 'say.)', 'waving', 'sorts', \"mouse!'\", 'tiny', \"cats?'\", 'says', 'ask.', 'wig,', \"story,'\", \"`you'd\", 'attempted', 'hurry:', 'dodged', 'dreaming', \"rabbit'\", 'animals,', \"mine.'\", 'truth:', 'accident,', 'feeble', 'placed', 'jury.', 'confused', 'incessantly', 'alice)--', 'other,', \"said,'\", 'very', 'practice', 'then', 'indignantly,', 'lewis', 'brain;', 'shut.', 'reading', 'sea!\"', 'roses', \"nonsense,'\", 'today.', '--come,', 'soup!', \"`ugh!'\", \"marmalade',\", \"what's\", 'caused', 'treated', 'waited', \"more!'\", \"for?'\", 'interest', 'it--once', 'splendidly', \"say!'\", 'temper,', 'moment:', 'whiskers!', 'larger:', \"couldn't\", 'larger', 'stairs!', 'plate.', 'respectful', \"alice's,\", 'dishes.', 'cautiously', 'least', 'passing', 'live.', 'hedgehogs', 'tougher', 'am', 'contradicted', \"not,'\", 'brush,', 'pour', 'merrily', 'velvet', \"muchness?'\", 'candle', 'rule,', 'do', 'out-of-the-way', \"caterpillar's\", \"puss,'\", 'pictured', 'rest', 'cheap', 'makes', 'fifth', 'pinched', 'noises,', 'hare.', 'tarts', 'chimneys', 'book', 'opened', 'dispute', \"getting!'\", \"needn't\", '`crumbs', 'spoon', \"bill,'\", 'seaography:', 'xii', 'fork', 'cares', 'holding', 'free,', 'tone:', 'stairs.', 'held', 'sleepy;', 'them--`i', 'fit)', 'games', '`certainly', 'entirely', 'sister,', 'ever:', 'tricks', 'anything', 'could,', 'rich', 'label', 'tried', 'best', \"next!'\", 'favoured', 'denial;', 'silence:', 'by--the', 'allow', \"this!'\", 'mind', 'fanned', 'hedgehog.', 'sobs,', '(as', 'sun.', \"turtle.'\", 'land', \"speaker,'\", 'opportunity', 'thunderstorm.', 'sight,', \"from?'\", 'hit', 'wind,', 'strings:', 'minutes.', 'her;', \"honour!'\", \"eggs,'\", 'fan!', 'salt', 'leaving', 'again', 'gloomily:', 'doubt,', \"little!'\", \"either!'\", 'particular', 'steam-engine', 'unpleasant', 'past', 'time.)', 'gryphon:', \"won't!'\", \"dogs.'\", 'suddenly', 'settling', 'eye', 'voice:--', 'passed', 'friend.', 'saying,', 'could', 'times', '`where', 'did', 'of', 'bite.', '`advance', 'yours.\"\\'', \"back!'\", 'rabbit!', 'replied;', 'king,', 'impatiently,', 'hunting', \"here,'\", '\"i\\'ll', 'jury-box,', 'waited.', 'ear.', 'tremulous', 'good-bye,', 'taking', 'soup,', \"`'tis\", \"derision.'\", 'sobs.', 'uncomfortable', 'condemn', 'visit', 'duck:', 'avoid', 'yours:', 'herself', \"shoes!'\", \"day,'\", 'usual.', 'deeply,', 'lowing', 'couples:', 'keep', 'baby', 'pope,', \"days.'\", 'ma', 'heavy', 'sneezing', \"ill.'\", 'spectacles,', 'knee.', 'up:', \"off?'\", 'bright', 'golden', 'prisoner', 'sight', 'next.', \"dormouse,'\", 'rabbit;', 'glaring', 'keep,', 'angrily', '`besides,', \"cakes,'\", 'character,', 'toys', 'closely', 'prize', 'feelings.', 'trouble,', 'grass', 'court,', 'rattling', 'knows', 'ones', 'flowers', \"`stupid,'\", 'once:', \"nothing.'\", 'three', 'begins', 'alarm', 'sulky', 'pretexts', 'chin.', 'grant', \"procession,'\", \"music.'\", 'surprise.', 'effect,', 'picture.)', 'cat.)', 'sternly.', 'sorry', 'thunder,', 'railway', 'expressing', 'queen:', \"different,'\", 'certain', 'suppose,', \"house!'\", 'thank', 'frying-pan', 'hedge.', 'riddles', 'last:', 'struck', \"they'd\", 'seeing', 'dears', 'cat,', 'eyes.--`tell', 'thump!', 'shape', 'save', 'night-air', 'is--\"birds', 'next!', 'ridge', \"something!'\", 'mouth', \"`why,'\", 'kissed', 'distraction,', 'applause,', \"escape!'\", 'diligently', 'fear', '`that', \"everything's\", 'patted', \"dogs?'\", 'remarked;', \"dancing.'\", 'dainties', '`give', 'plan,', 'bear:', 'luckily', \"be,'\", \"`nonsense!'\", 'listen.', 'est', 'then--she', 'what?', 'silence,', 'you!', 'gryphon;', 'e--e--evening,', \"king,'\", \"`nothing,'\", \"duchess?'\", '`without', 'hastily,', 'dismay,', 'however,', 'ourselves,', 'hot', 'thinking', 'wish', \"alice's\", 'has', \"table,'\", 'hung', 'downwards,', 'tide', 'faces.', 'queens,', 'remain', 'broke', 'capering', 'knowing', 'know--and', 'no', 'pig', 'rising', 'week:', '`boots', 'indignantly.', 'i?', 'notice', 'lifted', 'running', 'stuff?', 'twinkle--\"\\'', '`nearly', \"manage?'\", \"prizes.'\", 'advisable--\"\\'', '`--it', 'high.', 'sheep-', \"uglifying!'\", 'meekly', 'chimney,', 'enough--i', 'interrupted', 'stamping', 'appear,', \"child!'\", 'court.', \"to-day?'\", '`lives', \"annoyed,'\", \"removed!'\", 'owl', 'advisable', \"coward!'\", \"i!'\", 'proceed.', '`write', 'panting,', 'passage:', 'word', \"bed!'\", 'supple', 'foolish', \"proceed,'\", 'happens.', 'yelp', \"i,'\", 'speaking', 'word,', '(`i', 'crawled', 'fly', \"fun!'\", 'stuff', 'tea.', 'within', 'follow', '(she', \"that!'\", 'hatter.', 'perfectly', \"this?'\", \"duchess's\", 'send', 'london', 'lullaby', 'mad,', 'sit', 'contempt.', 'quite', 'now.', 'butter,', 'pause:', 'round', 'cart-horse,', 'nor', 'lest', 'awfully', 'pence.', 'unlocking', 'listen,', 'hers--she', 'against', 'become', 'queen.', 'indignant', \"way?',\", 'turtle.', 'fine', 'said:', 'mustard-mine', 'alive', 'lark,', \"i've\", 'dormouse,', 'burst', 'appeared;', 'height.', 'way?', 'seven', 'succeeded', 'things--everything', 'sounded', 'mouse,', 'guinea-pigs', 'scolded', 'appearance', 'drink', 'crab,', \"had!'\", 'dipped', 'lory,', 'promised', 'treacle', 'though,', 'white;', 'ugh,', 'hundred', 'more,', 'doubled-up', 'agony', 'vinegar', 'rome,', 'cartwheels,', \"verdict,'\", \"never')\", \"pun!'\", 'tongue', 'evidence', 'fell', 'march', 'mistake;', 'finished,', 'march--just', 'stupidest', 'mostly', 'kitchen.', 'to-day!', '`why,', 'delight,', 'over,', 'undo', 'if', 'brushing', '`everybody', \"nose';\", 'think,', 'doubtfully:', 'gryphon', 'again.)', '`by-the-bye,', '(dinah', 'sky!', 'best,', 'a-piece', 'burnt,', \"growing.'\", 'first.', '`first', 'ever;', 'true.)', 'carried', 'chapter', 'but', 'rabbit,', 'latin', 'pencil', \"executed.'\", 'again--\"before', \"thimble';\", \"too.'\", 'even', 'meanwhile', 'magpie', 'got', '\"up', 'likely', \"home,'\", \"serpent!'\", 'pencils', 'rest,', 'rule:', 'low,', 'words', 'talk.', 'crying', 'our', 'furiously,', 'game', 'one;', 'finger,', '`twenty-four', 'leaders,', 'many', 'meet', '`swim', 'houses,', 'playing', 'know--no', \"extremely--'\", \"fairly,'\", 'curiosity,', 'usual', 'dormouse', 'signed', 'gloves', 'worm.', 'earth', '`ten', '`cheshire', 'pretend', \"sobbing,'\", \"tea,'\", \"window.'\", 'flame', 'oh,', 'rise', 'days', 'bird', '`fury', \"`serpent!'\", '`but', \"bill!'\", 'smiled', 'lasted.)', 'lessons', 'marked,', 'executed', \"`fifteenth,'\", '\"--said', 'you,\"\\'', '\"let', '`pray', 'figure', 'delightful', \"`arrum.')\", 'nowhere', 'remarkable', 'sister', \"home?'\", 'large,', 'hint;', 'vague', 'lobsters,', 'piteous', 'arch', \"`that's\", 'cut', \"mind.'\", '`pepper,', 'remaining', 'beating', '(for,', \"now,'\", 'lost', 'pigeon;', 'other', 'twinkling', 'sizes', 'replied:', 'turn;', 'please:', \"know.'\", \"guilt,'\", 'mouths--and', 'wink', 'goldfish', 'shared', 'sleep', 'girl', 'mentioned', \"`why?'\", 'bottle.', 'telling', \"writing-desk?'\", \"one,'\", \"`very,'\", 'violence', 'wet', 'existence;', 'thoughtfully:', \"then!'\", \"here?'\", '--but', 'done', 'shingle--will', 'whistle', 'eyes--and', 'floor:', 'remembered', 'morning', 'thing,', 'dressed,', 'teacup', 'face--and', '\"uglification,\"\\'', 'him.', 'dry,', 'hurt', 'hopeless', '`with', 'filled', '`back', 'righthand', 'on;', 'moon,', 'meaning.', 'jaws', 'carroll', 'adventures,', '`mine', 'want', 'good', \"like.'\", \"he'd\", 'hearts,', 'out,', 'some', 'do.\"', 'in.', 'out.', 'alas', 'dogs', '`of', 'hair', 'you--all', \"sing,'\", '`three', \"else's\", 'elegant', 'altogether,', 'made.', 'ringlets', 'uncivil.', 'meaning', 'this:--', \"dormouse!'\", \"much,'\", 'on,', 'histories', 'extraordinary', 'thought),', 'lodging', 'emphasis,', 'length', 'mouse--a', '`fetch', 'arm-in-arm', '\"\\'tis', 'faces', 'owl,', 'walk!\"', 'knew)', 'simply--\"never', 'graceful', 'make', 'banquet--]', 'quarrel', 'tail.', 'tulip-roots', 'sneezed', 'shoulders,', 'girls', 'zealand', 'execute', \"names,'\", \"mouse's\", 'uncomfortably', \"trouble!'\", 'share', 'nothing,', 'globe', 'fury,', 'bee,\"', 'cat;', 'scroll,', 'get', 'middle,', 'loud', 'joined):--', \"us,'\", 'duchess,', '`sentence', \"wrong!'\", 'over.', 'farm-yard--while', 'yet--oh!', 'heard', 'turn-up', 'violently', 'rush', 'pause.', \"are,'\", 'ann,', \"yet,'\", 'takes', '`speak', \"time,'\", \"o'clock\", 'sigh.', '`and', 'indeed.', '\"keep', 'proud', 'top', 'fitted!', 'dive', \"that's\", '`digging', 'being', 'these', 'nothing;', 'spoon:', 'give', \"would,'\", 'easily', \"that.'\", 'ridiculous', \"enough!'\", 'setting', 'dead', 'dream.', \"impertinent,'\", \"conversation?'\", 'let', 'mile', 'cauldron', 'lately,', \"was.'\", 'alarmed', \"ache!'\", \"all.'\", 'rate', 'body', \"explained,'\", \"be?'\", \"no!'\", 'puppy', 'again.', 'bats?', 'yourself', 'happened,', 'bit.', 'over;', 'roof', 'bursting', 'seen,', 'doing', 'far', 'tone.', 'fancying', 'fair', 'beasts', 'seen:', '`an', \"concert!'\", 'threw', 'wider.', '`behead', \"game.'\", 'down!', 'child,', 'here,', 'back-somersault', \"weren't\", '`perhaps', 'growing,', 'hate--c', 'comfortably', \"dormouse's\", 'william,\"\\'', '`hold', 'pattern', \"they're\", 'silent,', 'brown', 'decidedly,', 'away:', 'uncorked', 'ran', 'school', 'voice,', \"behind?'\", '\"too', 'verse', '`very', 'disappeared;', \"coming!'\", 'bank,', \"think?'\", \"too,'\", 'from', 'any.', 'patiently.', \"jurors.'\", 'french', 'altogether', 'frog-footman', 'footman.', 'instantly,', 'course,', 'natural', '`she', \"dear,'\", 'suet;', 'peeped', \"`it'll\", 'down.', 'english);', 'swim--\"', 'hedgehogs;', 'driest', 'remarking', 'feathers,', 'first,', 'began.', 'muddle', \"about!'\", 'him:', 'morals', 'lips.', 'happened.', 'painting', 'grin', 'experiment', 'nearly', 'grins', 'cat!', 'skurried', 'hanging', 'addressing', 'bore', 'slates', 'breath.\"', \"girl,'\", 'little--\"\\'', 'noise', 'looking', 'flapper', \"first,'\", 'all:', 'procession', 'roses.', 'knowledge.', 'grinned;', \"do,'\", 'used', 'blew', '`--i', '`now', 'cat.', 'forwards', 'turned', 'nice', 'english,', 'kiss', 'i', \"likes.'\", 'follows:--', 'looking-', 'faint', 'sands', \"up,'\", 'dormouse;', 'pretty', \"treacle,'\", 'iii', 'leap', 'air', 'size', \"question,'\", 'mary', 'clean', 'hope', 'twist', 'serpent,', 'knocked.', 'wonder', \"man,'\", 'saucer', 'on', \"turtle's\", 'line:', 'creatures', 'shore.', 'twinkle,', 'uneasy:', 'miles', 'more;', 'speak.', '`--but', 'sang', 'hearing', 'garden,', 'shrimp', 'appear', 'more:', '`poor', 'rudeness', 'kneel', \"i--'\", 'upset', \"temper!'\", 'love).', 'helpless', 'holding,', \"animal's\", '`who', 'taught', 'pool,', \"chimney!'\", 'her,', 'imitated', 'tired', 'knot,', \"isn't,'\", 'spoke--fancy', \"window?'\", 'footman,', 'excellent', 'with;', 'knowledge', 'pool', 'hearts.', 'letter,', 'garden.', 'pulled', 'notion', 'eleventh', 'shut', 'meekly:', 'nibbling', \"say--that's\", \"is.'\", 'too,', \"caucus-race?'\", 'it', 'does', 'feelings', 'duck.', 'trying,', 'trials,', 'low.', \"direction,'\", 'stretching,', 'ann!', 'lives', 'zigzag,', 'wait,', 'welcome', \"course.'\", \"figure!'\", '(`which', 'time).', 'from:', '`why', 'know.', 'skimming', 'faintly', \"it,'\", \"witness!'\", 'whisper.)', 'pardon,', 'fond', \"`dinah's\", \"here.'\", 'rude,', 'telescope!', \"raw.'\", 'puzzled,', '`--yes,', \"baby?'\", 'just', 'able!', 'fashion,', 'roots', 'mock', \"majesty?'\", '`prizes!', 'tea-tray', 'back.', 'ordered', 'lobster', \"be!'\", \"opinion,'\", '`sure', \"say.'\", \"curious!'\", 'pleased.', 'off).', 'plan', 'up,', \"`i--i'm\", '`explain', 'hopeful', \"for.'\", \"nonsense.'\", 'complained', 'towards', 'answer,', 'children.', 'pat!', 'crash)--`now,', 'have', 'wherever', 'dance', \"`here!'\", 'close,', 'quietly,', 'hungry,', 'slippery;', 'sorrowful', 'bells,', '`oh!', 'day,', 'justice', 'in', 'reaching', 'english', \"order,'\", 'you:', 'yours', 'crowded', 'refused', '\"edwin', 'deep', 'them,', 'mind,', 'attempts', 'finished', 'mallets', '`flamingoes', 'started', 'nobody', 'crumbs', 'singers', 'drawling-master', 'snout', \"holiday?'\", 'soon', \"`you're\", 'knave.', \"together!'\", 'suddenly,', 'fainting', \"conqueror.'\", 'crab', \"mad.'\", 'i,', 'treat.', 'say,', 'offer', 'them--all', 'gone.', \"partner!'\", 'us,', \"`unimportant.'\", '`have', 'encourage', 'returned', 'jury,\"', \"removed,'\", '`--mystery,', 'children,', \"before,'\", 'say', 'shower', 'mouth;', 'happening.', 'morcar,', 'engaged', 'despair', 'directed', 'off', 'hare,', \"that,'\", 'sighing', 'guessed', 'arm-chair', 'my', 'cherry-tart,', 'plainly', 'hastily', 'corner,', 'uneasily', \"sister's\", 'planning', 'tongue,', 'folded,', \"doing!'\", 'listening,', \"business!'\", 'spoke;', 'really', 'chimney', 'thought.', 'declared', 'ah,', 'arms', 'roughly', 'lacie,', \"clever?'\", 'persons', 'barrowful', 'you.', 'killing', 'journey,', 'cannot', 'larger,', \"sky-rocket!'\", 'received', 'sign', \"`shan't,'\", 'duchess', '`take', 'off;', 'delight', 'used--and', 'eagerly,', \"`never!'\", 'subjects', 'sugar', 'wasting', \"up!'\", 'open', 'hare:', 'draw,', 'itself,', 'minutes,', 'someone', 'personal', 'joined', 'hand,', 'twice', 'crouched', 'replied', 'game,', \"cup,'\", \"do.'\", 'history.', 'sir,', \"oyster!'\", 'wood--(she', \"axes,'\", 'way--never', \"say?'\", 'children', 'it),', \"`don't\", 'dear', 'pegs.', 'edwin', 'arguments', 'mouths', 'ink,', 'brass', 'think;', 'pairs', 'cushion;', '(and,', 'woman--', 'bottom', 'inquisitively,', 'courage', 'for?\"\\'', 'childhood:', 'extremely', 'please!', 'flower-beds', 'that.', 'right-hand', \"`she'd\", 'eyes,', 'something;', \"mouse!')\", \"then!--bill's\", 'wants', 'nonsense', 'directions,', 'knee', 'come,', 'too:', '`now,', 'grief,', 'pounds!', \"bit.'\", \"down!'\", 'present--', 'and', 'pennyworth', 'gloves--that', 'undoing', 'flashed', \"toes?'\", '(when', 'learned', 'think!', 'duchess.', 'room,', 'escape,', '`what!', \"talk,'\", 'upon', 'pitied', 'twinkling!', 'bough', 'tea', 'bit', \"to.'\", 'home;', 'pocket,', 'reeds--the', 'late', 'guess,', \"off--'\", 'then?', 'triumphantly,', 'look-out', '`somebody', 'inwards,', 'geography.', '`go', 'door.', 'flurry', 'five.', \"answer?'\", 'pity.', 'wildly', 'fallen', 'vanished.', 'ran,', '`one,', 'queer-looking', 'eats', 'laughed', 'shutting', 'words:--', 'miss,', '`orange', 'pleased,', \"whiles.'\", 'airs!', 'daresay', 'baby,', 'doubtful', 'protection.', 'rabbit.', 'and,', 'gazing', 'dodo.', \"doing?'\", 'hot,', 'quarrelling', 'knowledge,', '`soles', '`to', \"happens!'\", 'jumping', \"kind,'\", 'spades,', 'minute', '`shall', 'thanked', 'candle.', 'changed,', \"much!'\", 'room.', 'timidly;', 'first--they', 'happen,', 'curtseying', 'bank--the', 'tone;', 'invited', 'this),', 'millennium', \"bird,'\", 'eyes:', 'tea--not', 'calmly,', 'voices', 'quick', 'choked', 'nicely', 'pictures', 'cries', 'bread-and-butter', 'say.', 'ways', 'carefully,', 'somehow', \"won't'\", 'family', 'race-course,', 'banks,', 'hear', 'least--at', 'dried', \"afraid,'\", \"school,'\", 'sight.', \"stairs!'\", 'pack,', 'impatiently;', 'fancy', \"lessons,'\", 'fan,', 'had', 'there', \"invited,'\", 'tumbled', 'outside.', \"ears--'\", 'yer', 'a', 'panther', 'pool--she', 'wow!', 'night?', 'always', 'note-book', 'bleeds;', 'house', 'sisters--they', 'can', 'chanced', 'other;', 'wondered', 'raising', 'grey', 'said', 'ready', 'fly;', 'strength,', 'window,', 'person', 'beheading', 'promising,', 'bat,', 'busy', 'relieved', \"know,'\", 'middle.', 'temper.', 'telescope', 'stopped', 'drop', \"afterwards.'\", 'often,', \"`yes!'\", '`till', 'tears.', 'business', 'hatter', '`seven', 'remember', 'certainly', 'then,', 'presents', \"let's\", 'producing', 'cleared', 'puppy;', 'turn', 'strange,', 'old,', 'story', 'fish,', 'reasonable', 'kettle', 'waistcoat-pocket,', \"window!'\", 'thatched', 'rope--will', 'garden:', 'pebbles', '`allow', 'over)', 'words,', 'undertone,', 'cautiously:', 'together', 'it?)', \"twice--'\", 'shaking', 'anything.', 'asking', \"dream!'\", 'saucepan', 'lizard', 'began:', 'nose--', 'lived', 'year', \"again,'\", 'to,', \"d,'\", 'feeling', 'nursing', 'flinging', 'new', '(for', 'touch', 'matters', 'closer', 'face', 'seaside', 'declare,', 'sound.]', '`thank', '`does', 'set', 'solemn', 'dunce?', \"sea.'\", 'that!', 'collected', 'twenty-four', 'six', 'table', 'rushed', 'comfort,', 'licking', 'pop', 'air,', '`important--unimportant--', \"somewhere,'\", 'dinah:', 'smallest', 'fit', 'jumped;', 'writing-desks,', 'subject!', 'cat:', \"hat,'\", \"longer!'\", 'to--to', \"answers.'\", 'spectacles', \"shorter.'\", 'calling', '\"how', 'upsetting', 'book,', 'faster', '`no', 'little!', 'sharing', 'did.', 'instead', 'first', 'wandering,', \"bit!'\", 'riddle', \"you're\", 'whistling.', 'died', 'get\"', 'mineral,', 'dinah!', 'audibly.', 'saucepans,', '`may', 'understand', 'feet!', 'size?', 'places--', 'find', 'kill', \"first.'\", 'uncommon', 'instance,', 'see:', '`do', 'gently', \"tongue!'\", 'lad!--here,', 'sigh:', 'questions', 'said,', '`whenever', \"below!'\", 'shock', 'ring,', 'lory.', 'glad', 'bag,', 'anything;', 'crown.', \"`everything's\", 'whiting', 'could!', \"pleases!'\", \"really?'\", '3.0', '\"french,', 'prevent', 'different,', 'suit', 'draw', 'splashing', 'queen', 'afraid', 'but,', \"wouldn't\", '(in', 'more--as', 'hours', 'than', \"then.'\", 'kitchen', 'bringing', 'purple.', 'out', 'morning?', 'squeezed', 'reasons.', 'flung', 'he', 'tone', 'alternately', 'flamingoes,', \"do?'\", 'sea', 'time', 'which', 'sentenced', '`change', \"was!'\", 'could.', 'sense,', 'atheling', '\"much', \"tortoise--'\", 'longed', 'procession,', \"roses?'\", 'month', 'buttercup', 'brave', 'edition', 'angrily:', 'ye;', 'depends', 'tumbling', 'die.', 'unusually', 'beloved', 'absurd', \"puzzle!'\", 'curious,', 'minutes', \"life!'\", \"know?'\", 'interesting,', \"don't!'\", \"guinea-pigs!'\", 'decided', 'stupid),', 'seven.', 'fancied', 'sorrows,', 'treading', 'dear:', 'cur,', 'king.', 'it.)', 'moderate.', 'remarked.', 'adventures', 'dears!', 'flavour', 'curls', \"dear?'\", 'sticks', 'muscular', 'never!', 'why,', 'written', \"outside.'\", 'affectionately', 'dormouse!', \"`dinah'll\", 'tea,', 'asleep.', \"myself.'\", 'way', 'english.', 'tittered', 'nurse!', 'beautiful,', 'smaller,', 'crept', 'pieces', 'soft', 'pleased', 'managed', \"then?'\", 'arms,', 'about.', 'tails', 'chrysalis--you', 'beau--ootiful', 'story.', 'rabbit:', 'cross,', 'so', '`really,', 'throne', 'box', 'hollow', 'shepherd', 'flown', 'stand,', '`as', 'mad--at', \"attending!'\", 'tinkling', 'birds', 'cold', 'trumpet', 'introduced', 'duck', 'honour,', '`living', 'alice,)', 'happens', 'claws,', \"perhaps,'\", 'moral,', \"`we're\", \"hatter's\", 'might', 'proves', 'wood', 'soldier', 'paws.', 'adventures--beginning', 'comes', 'be,', \"finished,'\", 'suddenly:', 'panted', 'courage.', '`nothing', 'miss', 'understood', 'none', 'everything', 'am,', 'editions', 'clock.', \"them,'\", 'without--maybe', 'scale!', 'court!', 'great', '`read', \"adventures.'\", 'seemed', \"grin,'\", 'hardly', 'cards:', 'tea;', 'shoulders.', 'saves', 'reading,', 'dropping', 'read:--', \"jaws!'\", 'head!\"\\'', \"think,'\", 'upset,', 'aloud;', 'considered', 'croquet-ground', 'afford', \"fashion.'\", 'execution.', '`you', 'thin--and', 'hurriedly', \"whatever?'\", '`can', 'knave,', 'players', \"thing,'\", \"stop.'\", 'speak,', 'begged', \"`well!'\", 'bats', 'ground', \"all,'\", 'themselves.\"\\'', 'bear?--mind', 'foot,', 'rabbit-hole', \"sir--'\", 'time.', 'impatient', 'comes,', \"be.'\", 'worry', 'together.\"\\'', 'difficulty', 'busily', 'slipped', 'smile.', 'moved', 'hands,', 'mark;', 'dry', 'vote', \"and-butter--'\", 'follows', 'country', \"ma!'\", 'poor', \"teases.'\", \"happen,'\", \"giddy.'\", \"her,'\", \"cat's\", \"figures!'\", 'trampled', 'bats,', 'scroll', 'dog', '`fourteenth', \"idea,'\", 'kindly', 'disappeared.', 'like:', 'actually', 'repeat', 'tones', 'dinn', 'lasted', \"draw,'\", 'away', '`each', 'escape', \"you'd\", 'bowed,', 'generally', 'care', 'slightest', 'child;', 'concluded', \"cats!'\", 'altogether.', 'sitting', 'proposal.', 'nice,', 'oh', 'pigeon', 'snatch', 'sand', '`repeat,', 'fading', 'sighed', 'sometimes,', 'liked,', 'conquest.', 'shining', '`consider,', \"does.'\", 'water,', 'ate', '`o', 'knock,', 'spectacles.', 'nobody,', 'garden--how', 'imagine', \"end,'\", 'eye,', 'to', 'rustled', \"rate,'\", \"court.'\", \"dull!'\", 'with,', 'place,', 'first--verdict', 'noticed,', \"majesty!'\", 'daisies,', 'invitation', 'terror.', \"sell,'\", 'wandering', 'two', 'father', \"choice!'\", 'remembering', 'lastly,', 'race', \"`there's\", 'alice:', 'blow', 'cattle', 'bright-eyed', 'over', 'dreadfully', 'dear,', 'beauti--ful', 'look', 'presented', 'scratching', '\"twinkle,', 'considering', 'happened', 'him--it', \"`treacle,'\", 'meat,', 'bread-and-butter.', \"hedge!'\", 'bristling', 'thirteen,', \"go,'\", \"pardoned.'\", 'given', 'chance', 'earth!', 'educations--in', 'listeners', 'impatiently:', \"day!'\", 'dozing', 'am!', 'footsteps,', 'home', 'flamingo:', 'his', \"sir,'\", 'languid,', 'cool', 'know,', '`begin', \"it'll\", 'retire', \"moment!'\", 'doubling', 'rubbed', 'sour--and', 'printed', \"curiouser!'\", 'speech,', '\"i', \"water-well,'\", 'away.', \"room!'\", 'fancy,', 'why', 'long,', 'five,', 'no,', 'company', '\"with', 'himself:', 'yet', 'result', 'neatly', 'called', 'kings', 'birthday', 'boldly:', \"things!'\", \"curious.'\", '`w.', 'taller,', 'cheered,', 'garden.\"\\'', \"it?'\", 'walking', 'now?', 'officer', 'lesson', 'uncomfortable.', 'bend,', 'hookah', 'judging', 'think', 'arches', 'minding', 'write', 'interrupted,', 'picking', 'murdering', \"over!'\", 'death.\"\\'', 'belong', 'unable', 'it;', 'ago:', \"sad?'\", 'wonderland,', 'rats', 'turtle', 'days.', 'minded', '(luckily', 'pity', 'ugly;', \"cat,'\", 'hookah,', 'told', 'right', 'finding', 'cook.', \"partners--'\", 'beginning', 'hatter;', 'bowing', 'cheated', \"people,'\", 'please', 'piece', \"execution.'\", 'creep', 'each', '`which', 'happen', 'trotting', 'shrieked', 'tastes!', 'arrow.', 'me,', 'changes', 'tossing', 'was)', 'rat-hole:', 'possibly', 'away,', 'were', 'worse.', \"executioner's\", 'rapped', 'are', 'persisted', \"`no,'\", 'proved', 'sensation', 'eaglet,', \"whatever,'\", 'wearily.', 'small.', \"first!'\", \"did,'\", \"say,'\", \"whiting!'\", 'witness', 'nearer', 'direction', 'savage', 'choke', 'soldiers,', 'hedgehogs,', 'tea-things', \"now--don't\", 'it:', 'done,', 'guinea-pig,', 'among', 'lit', 'interesting.', 'sea,', \"story!'\", '`talking', \"do!'\", 'prizes.', 'question,', \"indeed!'\", '\"purpose\"?\\'', 'explanation;', 'are;', 'moved.', 'tears!', \"figure,'\", 'squeeze', 'executioner,', 'table:', '\"he\\'s', 'remark.', 'bawled', 'interrupted.', 'tail;', 'double', 'door--i', 'rose-tree,', \"sea--'\", 'it!--that', \"shall!'\", 'uglify', 'swim', 'croqueting', 'eager', 'finishing', 'come', 'history,', 'capital', 'lovely', 'paris,', 'does.', 'well,', 'chief', 'fountains.', 'played', \"pig!'\", 'denies', 'invented', 'forehead', '\"who', 'crash', 'going', 'rapidly:', 'arm,', 'accounts', 'search', 'next', 'sea.', 'thrown', 'paused', 'natural);', 'yawned', 'fond--of--of', 'circle,', '`serpent,', '`just', \"dance,'\", 'below', \"william,'\", 'day!', 'pepper', 'mistake', 'nose;', 'then--always', 'for', 'sneezing.', 'king;', \"refreshments!'\", 'lessons,', 'viii', 'bring', 'particular--', 'boxed', \"child,'\", 'thistle,', '`up,', \"`important,'\", 'puzzling', \"'tis\", 'tucked', 'pattering', 'unhappy.', 'is--\"take', 'asleep', '`in', 'ignorant', 'leading', 'hurt,', 'this', \"sing?'\", \"him.'\", 'advance!', \"verses.'\", 'was:', 'silent.', 'serpents!', 'yet--and', '`tell', \"can,'\", 'executioner', '`drive', 'way!', 'sneezes;', 'sleep,', 'blame', 'clear', 'court,\"', '`at', 'may', 'manner', 'glass.', 'soldiers', 'on:', 'canvas', 'fireplace', 'pocket', 'certain!', 'air.', 'tale,', 'sides', 'particular.', 'shoulder', 'swimming', 'funny', 'those', 'respectable', \"duchess,'\", 'somersault', \"a--'\", 'nose', 'caterpillar,', 'aloud.', 'herself,', 'dish?', 'paper.', 'turtle,', 'life', 'kind', 'fish', 'call', 'water.', \"matter,'\", 'fall,', '(and', 'besides', 'head,', 'hiss', 'jury-box', 'signifies', 'dates', \"`ahem!'\", 'chorus,', 'guests,', 'rule', 'put', 'quickly', '`only,', 'long;', '`here!', 'insolence', 'down:', \"talking!'\", 'are!', 'went.', 'bread-', 'age', 'voice;', 'much', \"treacle-well.'\", 'found:', 'whisper', 'flamingo.', 'neat', 'hatters', 'moment,', 'dreamed', 'sleep\"', \"unimportant--important--'\", 'home!', 'finish', 'still', 'yesterday', 'dream:--', 'certainly:', '`your', 'did:', 'not,', 'passionate', \"m?'\", \"not?'\", \"handwriting?'\", 'wise', 'went,', 'hated', 'any', 'murder', 'though', 'never', \"talk!'\", 'free', 'balls', 'herself.', 'pigeon,', 'baby;', 'neighbouring', \"`where's\", 'croquet-ground.', 'size:', 'bread-and-butter,', 'verses', 'pine-apple,', \"question?'\", 'wooden', 'drawling--the', 'go', 'handsome', 'knew,', \"english!'\", 'itself', 'foot', \"lessons?'\", 'hoped)', 'taller', 'execution--once', 'farmer,', 'listen', 'growing', 'officers:', \"sort,'\", 'beheaded,', 'brought', 'ravens', 'feet', 'themselves', 'uncommonly', 'bathing', 'though.', 'coming.', \"dinah'll\", 'hurry', '`\"--found', '`when', 'rate:', 'will', 'seem,', 'glass,', 'comfits:', 'pieces.', 'was', 'them--and', 'one!', 'nonsense.', \"i'm\", 'door', 'unjust', 'manner,', 'end!', 'leaves.', 'and--oh', 'obstacle', 'knee,', 'creature,', 'knife,', 'drew', 'consented', 'fire,', 'else', 'hurried', \"with.'\", 'first;', '`sit', 'minute.', 'him),', 'favourite', 'as', 'reply.', 'inside,', 'tone,', 'delay', '`is', \"liked.'\", 'stirring', 'paw', 'on?', 'choice,', 'hungry', 'accustomed', \"wig.'\", 'subject', \"temper,'\", 'serpent.', 'fan', 'garden', 'such', 'along--`catch', 'losing', '`collar', '\"it\"', 'thought:', '`not', '`sure,', 'night', 'would,', 'getting', \"they've\", 'sense', 'so.', 'again!', \"like,'\", 'cried', 'lost:', 'swim,', 'rabbits.', 'sister;', 'myself', 'child:', 'think:', 'manners', 'frighten', 'stiff.', \"other.'\", 'law:', '(a', 'toes', 'mouse.', 'speak', 'gained', 'splashed', \"spot.'\", \"begin.'\", \"indeed,'\", 'indeed:--', \"butter,'\", 'anxious', 'kick,', 'ancient', 'turtle:', 'feel', '`if', 'skirt,', \"less,'\", 'multiplication', \"way--'\", 'usurpation', '\"you', 'expression', 'growls', 'alice!', 'chuckled.', 'executioner:', 'hastily.', \"far,'\", 'england', 'doors', 'hoarse,', 'permitted', 'knuckles.', 'hour', 'pack', 'whole', 'oneself', 'way:--', \"better';\", \"`once,'\", 'cause', 'tidy', 'wandered', '`unless', 'leaves:', 'until', 'bad,', \"them.'\", 'hippopotamus,', 'invent', 'sorrow,', 'hair.\"', 'middle', '`then', 'slates,', 'breeze', 'high:', \"`--where's\", 'corners:', 'things!', \"see,'\", 'key,', \"suppose?'\", 'old', \"brother's\", 'sharks', 'nasty,', 'dream,', 'singers.', \"yet?'\", '`eat', 'kept', '`ah!', 'talking', 'him,', 'lazy', 'roast', '`dear,', 'deeply', 'else.', \"yet.'\", '`he', 'overhead;', 'lobster;', \"there's\", 'smoke', 'settled', 'see\"!\\'', 'steady', 'quadrille', \"with,'\", \"we're\", \"`hjckrrh!'\", 'nile', \"simpleton.'\", 'loudly.', 'feeble,', 'contemptuously.', 'world!', 'confusing', \"bill's\", 'before.', \"never!'\", 'talking:', 'brightened', \"alone!'\", '`there', 'begun', 'high,', 'saw.', 'own.', 'himself', 'answered,', 'silent', \"wasn't\", 'gravely.', 'serpent;', 'writing', 'twinkled', 'distance', 'rustling', 'humble', 'venture', 'escape;', 'purring,', '`same', 'things--i', \"things?'\", \"right?'\", \"think!'\", \"on!'\", 'oblong', 'wood.', 'felt', 'brown,', 'contemptuous', 'nurse', 'mean', 'dream', 'narrow', 'poker', 'consider', 'upright', 'sooner', 'move.', 'overcome', 'exclaimed', 'somebody,', 'before,', 'tie', 'worth', 'branches,', \"witness,'\", 'bill,', 'currants.', \"hedges,'\", 'disagree', 'managing', 'remarked,', 'timidly', \"once.'\", 'distant', 'sneezing,', \"me?'\", 'trembling', 'go,', 'flying', 'left,', \"last!'\", 'all', 'animal', 'follow,', 'white,', 'mine,', 'bother', 'custard,', 'one,', 'sing', 'an', 'resource,', 'now', 'produced', 'squeaked.', 'singing', 'sixpence.', 'insult', 'addressed', \"draw?'\", 'in:', 'impossible', 'gryphon.', 'be\"--or', 'knife', 'fetch', 'whispered,', 'sulky,', 'blasts', 'this;', 'white', 'speaking,', 'tight', \"elbow.'\", 'heels', 'names', 'lady', 'earth.', 'sharply', 'pleasanter', 'feebly', 'lefthand', 'queer-', 'jury', \"wow!'\", 'marked', 'cheeks,', 'lamps', 'louder', 'green', \"beginning,'\", 'questions.--how', 'knew', \"know!'\", 'floor,', \"alive!'\", 'means,', 'fury:', 'elbow', 'two,', 'downward!', 'once,', 'present', 'voices--`hold', '`please', \"tomorrow--'\", 'howled', '`drink', '`hush!', \"we've\", 'lying', 'change', 'angry.', '`consider', 'peeping', 'swallowed', 'wept', 'son,', 'she,', 'left', 'eel', \"right!'\", 'stop', 'cucumber-frames', \"she'll\", 'jury,', \"somebody.'\", 'dancing', '`from', 'birds!', 'underneath', 'doze;', 'advice', 'caucus-race', 'corner--no,', 'passion,', \"in.'\", 'sky.', \"you've\", \"asleep,'\", 'ask!', \"enough,'\", 'confusion', 'with.', 'marched', \"late!'\", \"find?'\", \"shouldn't\", 'disgust,', 'grammar,', 'rabbit', 'politely:', 'off.', \"pie--'\", 'tail,', \"mushroom,'\", 'comfits,', \"trying--'\", '(with', 'second', 'fur.', \"twelfth?'\", 'yelled', 'green,', 'work', \"think.'\", 'snail.', 'time!', 'narrow,', 'alive;', \"are!'\", 'pointing', \"growling,'\", 'footmen,', 'grave', 'raving', 'living', 'fortunately', 'sounds', 'somewhere', 'hatching', 'sneezes:', 'true):', 'blades', 'altogether;', 'forget', 'who', 'locks,', \"one?'\", 'returning,', 'woman;', 'trial:', 'gallons', \"she's\", 'sharply,', \"dreadful,'\", 'us!\"\\'', 'treacle-well--eh,', 'like\"!\\'', 'muttered', \"meant,'\", 'once', 'difficulties,', '(we', 'staring', 'list,', 'stole', \"won?'\", \"finished.'\", 'eyelids,', 'alas!', 'appeared', \"see.'\", \"court!'\", 'reality--the', 'nothing.', '`explanations', \"must,'\", 'twelve', 'curiosity.', 'five!', 'appearing', 'this.', 'belt', 'pigs', 'see--how', 'dripping', 'further.', 'mine--a', 'triumphantly.', 'bat!', 'fit--\"', 'smoking', '`his', 'riper', 'coming', \"m--'\", '`suppose', \"hush!'\", '(though', \"means--to--make--anything--prettier.'\", \"somewhere.'\", \"lobsters!'\", 'alone', 'signify:', 'mad', 'him;', 'was,', 'made', 'sob,', 'lizard,', \"moment's\", 'alice', 'forgotten', 'work,', 'house,', \"fig?'\", 'shouted', 'what', 'offended', \"coils.'\", 'waistcoat-', 'tree.', 'usual,', 'tillie;', 'immediately', 'month,', 'field', 'breathe\"!\\'', 'giving', 'wretched', 'deepest', 'neck,', \"serpent?'\", 'flamingo', 'lobsters', \"mind!'\", 'when', \"minute!'\", 'fact.', 'sound', 'tureen!', 'continued', 'important', 'conqueror,', 'shillings', 'gloves.', 'is--oh', \"fancy--who's\", 'introduce', 'hedgehog', 'indeed:', 'wonderful', '`oh,', 'was!', \"ever,'\", \"like!'\", \"not';\", 'flat', 'began,', 'vanished', 'hint', 'slate', 'deal:', 'fighting', 'forgot', 'her:', 'stop.', '`--likely', 'soo--oop', 'added,', 'serpents', 'effect', 'gone', 'without', 'common', 'beautify', 'thick', 'simple', 'goose!', 'reason', \"queen's\", '`shy,', 'afore', \"plan.'\", 'hare', 'tipped', '`chop', 'flat,', '`all', 'stingy', 'answer.', 'life,', 'terribly', \"stupid?'\", 'denied', 'telescopes:', 'face,', '`seals,', \"sea,'\", 'furrow', 'anger,', 'gone,', 'lay', 'denying', 'tea-time,', 'possible', 'thimble,', 'ought!', \"man.'\", 'cakes,', 'occasional', 'bottle', 'only', 'managed?', 'soo--oop!', 'meant', 'authority', 'pool?', 'party', 'more.', 'hate', 'executed,', 'us', \"little,'\", 'them:', \"garden!'\", 'trims', 'order', 'thoughtfully', 'red', 'argued', 'moral', 'good,', 'mushroom,', 'everybody', 'why.', \"time?'\", 'court;', 'fumbled', 'toast,)', 'frontispiece', \"bat?'\", 'book-shelves;', 'tell', 'cry', 'wings.', 'stood', 'beast,', '`well!', 'recovered', 'anything,', 'swam', 'burning', 'clearer', 'evidently', \"off.'\", 'love,', 'smile:', 'side.', \"queen,'\", 'round.', 'something,', \"head's\", 'affair,', 'eggs,', 'immense', 'soothing', 'duchess;', 'hall,', 'pig-baby', 'thing.', 'trial', 'decidedly', 'then;', 'butter', \"one.'\", 'screamed', 'please,', '`hm!', 'that,', 'laughing', 'ventured', \"`poison,'\", 'alice,', 'him,)', \"you,'\", 'yet,', '`--so', 'child-life,', 'desperately:', 'hair!', '(alice', 'another', '`thinking', 'fix', 'looked', 'pity!\"?\\'', 'sprawling', \"pardon!'\", 'entangled', 'pray', 'play', \"watch,'\", \"`can't\", 'scream', 'that', 'silence.', 'different.', \"through,'\", 'finger;', 'terms', 'turtle--we', \"carrier,'\", '`would', 'almost', 'adjourn,', 'dropped,', 'taken', 'me', 'mabel', 'up', 'dishes', 'paws', 'dormouse.', 'master', 'ceiling,', 'eat', 'whatever', 'mine', 'reply', 'easy', 'it!', 'gravely,', 'buttons,', 'going,', 'shall', 'creature', 'large', 'plate', \"slates'll\", 'offended.', 'trees,', 'chorus', 'gloves,', \"dinn--'\", 'better', 'puzzled.)', 'none,', 'drinking.', 'grazed', 'summer', 'took', 'askance--', 'with', 'sadly', 'use', 'learn!', 'quiet', 'prosecute', 'vii', 'mournful', 'advance', '`get', \"shan't\", \"beginning!'\", 'stalk', \"ordered';\", 'again,', 'grin,', 'mouse-traps,', 'pink', 'every', 'mouth,', 'youth,', 'having', \"sea-shore--'\", 'beg', '`the', \"mean,'\", 'duchess!', 'bend', 'sighing.', \"`i've\", 'is--\"oh,', '`never', 'sure,', 'shelves', 'shrink', 'course', 'ten', 'rose', 'pair', 'pale', 'nodded.', 'guests', 'kindly,', 'are,', '`because', \"song?'\", 'slipped,', \"two!'\", 'voice.', 'fright.', 'lives.', 'grand', 'break', 'alice.', 'directly.', '`come', 'high', 'instantly', \"ask.'\", 'mabel!', 'offend', 'queer', \"shan't!\", \"caucus-race.'\", 'croqueted', 'size;', 'timid', 'hearthrug,', 'air!', '`come,', 'myself,', 'generally,', 'finger', 'backs', 'folding', 'ground--and', 'sigh,', 'ashamed', 'happens;', '\"what', \"feeling!'\", 'mean,', 'leaves', 'impossible.', 'canary', 'besides,', 'sure;', 'mouse--to', 'flustered', 'thoughtfully.', \"'em\", 'inches', \"me.'\", 'believed', 'learning', 'me?', \"well?'\", \"evidence,'\", 'mabel,', 'do:', 'see,', 'waiting', \"`who's\", 'seems', 'dish', 'centre', 'encouraging', 'account', '`--for', 'appeared,', \"before.'\", 'moving', 'state', 'walked', 'shoulder,', \"these?'\", \"to-day.'\", 'tea-time.', 'cook', 'creatures.', \"that?'\", \"weeks!'\", 'pleasing', '`hand', 'rock,', 'stockings', 'unless', 'chains,', 'eat\"', 'stays', 'while,', 'hoarse', 'another!', 'it,)', 'moment', \"again?'\", 'cake,', 'tut,', \"`i'd\", 'flew', 'spoke,', 'readily:', 'tasted', 'less', '`turn', \"didn't,'\", 'day.', 'enormous', 'learn', 'wrong', 'dinah,', 'speech.', \"fellow?'\", 'own', 'ordered.', 'trot', 'curving', 'northumbria--\"\\'', \"with?'\", 'music,', 'bit,', 'look!', 'cats', \"again!'\", 'whether', 'shrieks,', 'quarrelled', \"yourself!'\", 'spoken', 'bound', 'sent', 'do:--', 'go.', 'desperate', 'sat', 'soon.', 'began', '`yes,', \"altered.'\", 'absence,', 'begin', 'finished.', 'draggled', 'scream,', 'least,', 'whom', \"`silence!'\", 'fanning', \"late.'\", 'you', 'lonely', 'room', 'thoughts', 'older', 'whiting.', 'exclamation', \"wits!'\", 'note-book,', 'queen,', 'haste,', 'yourself,', '`their', 'sweet-tempered.', 'shyly,', 'hearing.', 'temper', 'laugh;', 'slates.', 'rippling', 'morsel', 'soup,\"', 'means', 'solemnly', 'fountains,', 'frog', 'stay', 'limbs', 'knocking,', 'gave', 'fish-footman', 'never-ending', 'jack-in-the-box,', 'number', 'stand', 'ready?', 'by', 'faces,', 'familiarly', 'softly', 'meeting', 'eagerly', 'anxious.)', 'shoes', 'walk', 'pass', 'loud,', 'speed', 'deal', 'chin', 'otherwise,', 'since', 'frog;', 'eyes;', 'front', \"learn?'\", \"ma'am,\", 'sleepy', \"queen?'\", 'shouting', 'winter', '`bring', 'humbly:', \"so,'\", 'turkey,', \"soup!'\", 'three-legged', 'conclusion', 'understand.', 'neck', 'replied,', '`silence', 'pie', 'gardeners', 'trial,', 'to?', 'word)', 'coast', \"is,'\", '`exactly', 'puzzled', 'into', '`wow!', 'mouths.', 'queerest', \"trying.'\", 'end:', \"english,'\", 'beds', 'suppressed.', 'closed', 'goes', 'arithmetic--', 'waste', 'throw', 'turtles,', \"beheaded!'\", \"`they--you've\", 'key', \"cutting,'\", 'angrily,', 'short', 'angry', '`any', 'acceptance', \"high,'\", 'general', 'key;', \"case,'\", \"`they'd\", 'leave', 'both', \"heard!'\", \"lower,'\", 'ours', 'cunning', 'eggs', 'part', 'foot.', 'conduct', 'secret,', 'shiver.', \"(`that's\", 'mouse?', 'unfolded', 'is', \"ground.'\", 'unwillingly', \"twinkle--'\", 'shook', 'mice--oh,', \"star-fish,'\", 'came,', 'courage,', 'quick,', 'again;', 'respect.', 'sure', 'do.', 'crashed', '`\"miss', \"bite,'\", '`what', 'nothing', \"fellow!'\", 'wander', 'walrus', \"he?'\", 'twenty', 'interrupting', '`--or', 'things', 'provoking', 'change:', '--the', 'near', \"to--'\", 'cheshire', 'bitter--and--and', 'end', 'down--here,', 'sun,', 'reach', \"crumbs.'\", \"wood,'\", 'pale,', 'door:', 'boon,', '`look', 'their', \"you?'\", 'else\"--but,', 'done.', 'balanced', 'fly,', '`until', 'riddles.--i', \"she'd\", 'finish,', 'crash,', 'passage,', 'sentence', 'once;', 'fixed', 'hurry,', 'head:', 'nurse--and', 'again:--', \"it's\", 'clapping', 'him', 'solid', 'atom', 'sort.', 'now,', 'good-naturedly', \"savage!'\", 'curly', 'hand', 'did,', \"didn't!'\", 'the', 'plates,', 'again:', \"business,'\", 'blacking,', 'before', 'loveliest', \"where.'\", 'finds', 'furrows;', 'rabbit-hole--and', 'peering', 'door;', '`we', 'that:', 'pressed', '`then,', 'water', 'different', 'pray,', \"egg!'\", 'hall.', 'five', 'turtles', 'directly,', 'sky', 'bone', 'fender,', 'tarts?', 'doubt:', 'effect:', 'between', '`ou', 'entrance', 'suppressed', 'fulcrum', \"hadn't\", 'mushroom', 'win,', 'indeed,', 'edgar', '`twinkle,', 'stool', 'mouse--o', 'washing', 'known', 'mouths;', '(the', 'curtsey', 'last', 'heart', \"`he's\", 'twentieth', 'officers', \"lobster--'\", 'explain', 'asking!', 'her', 'delighted', 'gardeners,', 'doorway;', 'asked.', 'chorus.', \"saying.'\", 'something', 'gay', 'pat,', 'pronounced', 'surprised,', 'wet,', \"prizes!'\", 'daughter', 'her.', \"were',\", 'here?', \"not!'\", 'wide', 'rapidly;', 'you--are', 'remarking,', 'trees', 'slowly,', '`right,', \"all?'\", 'regular', 'labelled', 'talk:', 'growled', \"croquet.'\", 'muttering', 'cucumber-frame,', \"verse.'\", \"wonder?'\", 'sudden', 'sure!', 'truthful', '(or', 'followed', 'is!', \"`you've\", 'comfortable,', 'drunk', 'relief.', 'whisper,', 'night!', 'shore,', 'that--only', \"here!'\", 'passage', 'books,', \"youth,'\", 'mouse:', 'sight;', 'gravy,', \"breathe.'\", '`curiouser', \"can--'\", '\"they', \"`stolen!'\", \"`alice!'\", 'table,', 'after-time,', 'agree', \"the--'\", 'feet,', 'glass', \"mind,'\", \"day.'\", 'slates;', \"rabbit's--`pat!\", \"remember,'\", 'wondering', 'particular;', \"waist,'\", 'turning', \"life.'\", 'fills', 'opening', 'leaves,', 'feather', 'exclaimed,', \"won't,\", 'silence', 'answer', 'laid', 'all.', 'trusts', 'does,', 'fire-irons', 'week', 'here', 'afterwards,', 'know', 'slate-pencil,', '(which', 'spreading', 'grand,', 'then--i', '`a', 'grown', 'live', 'cardboard.)', 'crocodile', \"crumbs,'\", 'twelve,', 'help', 'confused,', \"`i'll\", \"knocking,'\", 'doubt', 'soup', 'after', 'reminding', 'jogged', 'cost', 'name:', 'melancholy', \"see!'\", 'jurymen.', 'others.', \"march.'\", 'flappers,', 'eaglet', 'locked;', 'alone.', 'all!', 'plenty', 'life!', 'glass;', 'remarked:', 'punished', 'o', '[later', '`only', 'grinned', 'neither', 'law,', \"mostly,'\", 'curled', 'honour:', 'nervous,', 'so--and', 'catching', \"on?'\", 'courtiers;', 'also', 'resting', 'dodo,', 'afraid,', 'caterpillar;', \"throat!'\", 'lock,', 'exact', 'cupboards', 'magic', 'ointment--one', 'table.', \"maybe,'\", 'thought;', 'nervous', 'late,', 'settle', 'dears?', 'helped', 'further', 'uglification,', 'around,', 'exactly', \"speak?'\", 'age,', 'absurd,', 'uncomfortable,', 'few', 'appealed', 'hurry.', 'sight:', 'upstairs,', 'hours,', \"mayn't\", 'won,', 'tells', '(not', 'antipathies,', 'turtle;', \"dinner!'\", 'picked', 'advice,', 'name', 'pig,', 'injure', 'clock', '`so', 'seriously,', 'ending', 'itself,)', 'furious', 'climb', 'jaw,', \"sea!'\", 'things,', 'charges', 'natured,', \"all!'\", 'court', 'pigs,', 'nose.', 'height', 'empty:', 'queen!', 'ugly', 'song', 'bill!', 'longitude', 'forty-two.', 'fat;', 'passion.', 'ridges', 'dinner,', 'one', 'clubs;', \"on.'\", 'song,', 'pet:', '`--change', 'red-hot', 'patiently', \"lizard's\", 'cats:', 'too', 'scrambling', 'listening:', 'she', 'interesting', 'inkstand', \"part.'\", \"ada,'\", 'faster?\"', 'head', 'see', 'clinging', \"`moral,'\", \"jury--'\", '`two', 'like,', \"this,'\", \"nonsense!'\", \"then,'\", \"warning,'\", 'therefore', 'hands;', 'off,', 'across', 'enough;', 'slate--oh,', 'eaten', 'show', \"you!'\", 'box--', '`--you', 'doth', 'stigand,', \"`idiot!'\", '`mary', '`my', \"book,'\", 'joys,', 'laughed,', 'began:--', 'hall;', 'trouble', 'pie-crust,', \"`jury-men'\", 'other:', '`it', 'open,', 'unrolled', 'exclaimed.', 'best.', 'here;', '`leave', 'on!\"', \"`yes,'\", 'worse', 'morning,', 'beautifully', 'sadly.', 'day-school,', 'complaining', \"sisters,'\", 'out.\"', 'suppress', 'putting', '`either', 'mischief,', 'jurors', 'asked,', \"any,'\", 'rightly', 'it.', \"witness.'\", \"morning,'\", 'diamonds,', 'watch', \"course?'\", 'leaning', 'man', 'nine', '`once', \"you.'\", 'me!', 'roared', 'real', \"know--'\", 'curtain', 'quicker.', 'snorting', '`--and', 'arm', 'side,', 'thoroughly', 'daisy-chain', 'there,', 'guinea-pig', \"where--'\", \"puppy's\", 'gloves:', 'nearer,', '`please,', 'sharply;', 'teeth,', '`one', 'shrinking', 'messages', 'rules', 'them', 'whose', '`stand', 'already', \"end.'\", \"mystery,'\", 'enjoy', 'much,', 'kid', 'be', 'saying', 'eye;', \"she,'\", \"true,'\", \"`it's\", 'air:', '`--as', 'distance--but', 'ledge', 'low-spirited.', 'caterpillar.', 'small,', 'hide', \"three.'\", 'hedgehog,', 'deserved', 'anger', 'hers', 'together.', '`nine', 'shake', 'your', \"dog's\", 'porpoise,', 'examining', 'dormouse:', 'sharply.', \"subject,'\", 'barking', '`found', 'earls', 'accident', 'you?', 'encouraged', 'uneasily,', \"rabbit's\", 'adding,', 'fur', 'here.', 'showing', 'duchess:', 'spoke', 'x', \"majesty,'\", '\"come', 'bill', 'begin,', 'straightened', 'conversation.', 'nose,', '(pointing', '(it', 'powdered', 'yawning.', 'eagerly:', 'branch', 'him!', \"what?'\", 'shakespeare,', \"yourself.'\", 'day:', 'offended,', 'france--', 'shriek,', 'king', 'snail,', 'idea', 'friend', 'squeaking', 'persisted.', \"porpoise.'\", '`call', '`or', 'feared', \"in?'\", '`herald,', \"business?'\", 'abide', '`they', 'rome--no,', 'little,', 'remained', 'difficult', 'where', 'nest.', 'fishes', \"grin.'\", \"jury-box,'\", 'quadrille,', 'fidgeted.', 'red.', 'ambition,', 'conclusion,', \"pace,'\", 'goose,', 'led', \"yet!'\", 'oldest', 'startled', 'herself;', 'variations.', 'dear!\"', 'sits', 'cried.', \"believe.'\", 'processions;', 'clasped', 'earnestly,', 'opened,', 'toss', 'people', \"is--'\", \"think--'\", 'at!\"', 'nibbled', \"telescope.'\", \"wine,'\", 'remarks,', 'fact,', 'back', \"cards!'\", 'matter', 'porpoise', 'asleep,', 'heap', 'had,', 'believe', 'juror', 'burn', \"outside,'\", 'thought,', 'raven', \"king's\", 'way,', 'to-night,', 'frowning,', 'tiptoe,', 'bark', \"advantage,'\", 'hoarsely', 'knave', 'remarked', 'baby:', 'rather', 'wriggling', 'anywhere', \"waiting!'\", 'paris', 'poured', 'together,', 'argument', 'engraved', 'digging', 'woke', 'hall', 'bottle,', 'also,', 'noticed', 'several', 'became', 'this,', '`off', 'heads.', \"which?'\", \"story.'\", '\"there\\'s', 'taste', 'hand.', 'yawning', 'list', 'energetic', 'that;', 'checked', '`no,', 'spell', 'loudly', 'voice:', 'pressing', 'lost,', 'stoop', 'wood,', 'door,', 'head.', '(look', 'rate,', 'promise.', 'now--but', 'solemnly.', 'rumbling', 'tears', 'expected:', 'memorandum', 'stopping', 'crossed', \"railway,'\", 'caught', 'annoy,', 'questions,', '`really', \"bats?'\", '`how', 'day;', \"heads!'\", 'assembled', \"well--'\", '`whoever', 'drawing', \"sorrow?'\", 'turns,', 'sobbed', 'grinning', \"knot!'\", 'near.', 'him--how', 'loose', 'hatter,', \"bread-knife.'\", 'fish)--and', 'name,', 'ask:', 'counting', \"prisoner's\", 'fellow!', \"`i'm\", \"to?'\", 'punching', 'speak--and', 'violently,', '(before', 'stupidly', 'puzzled.', 'stoop?', 'go!', 'went', \"it--'\", \"again.'\", 'said,)', 'grass,', \"`what's\", '`--that', 'talk', 'stretching', \"housemaid,'\", 'full', 'shade:', 'howling', 'advantage', 'faster,', 'life;', 'pleasant', 'throwing', 'passed;', 'standing', \"away,'\", \"game,'\", 'pretending', \"plan!'\", '`was,', 'seem', 'dull', 'happened.)', \"tasted--'\", 'nevertheless', 'newspapers,', 'wife;', 'remark,', 'little', 'patience', 'ladder?--why,', 'noticing', 'shifting', \"him,'\", \"isn't\", 'enough,', \"them--'\", 'fits,', '*', 'so,', 'm,', 'indeed', 'bowed', 'spoke.', 'that?--it', \"toes.'\", \"can't\", 'fellows', '`\"will', 'memory,', 'inquired', 'politely', \"quadrille?'\", \"not.'\", 'eaglet.', 'circumstances.', 'interrupt', 'tremble.', 'occurred', 'hare,)', \"`wouldn't\", 'positively', 'thought', 'same', 'world', \"means.'\", 'players,', 'gather', 'longer', 'position', 'sad', 'cackled', \"chatte?'\", 'seldom', 'folded', 'more', 'pigeon.', 'sneeze,', 'repeated', 'others', 'outside,', 'hall:', \"tea--'\", 'glass.)', 'life.', 'rose-tree', 'harm', '`reeling', \"well,'\", 'except', 'forgetting', 'himself,', 'rubbing', 'ornamented', 'declare', 'improve', 'sleepy,', 'frightened', \"off,'\", 'row', 'most', 'suppose', 'deny', 'shaped', 'reason,', 'timidly.', 'mouse--of', \"grunt,'\", 'carrying', 'somebody', 'lap', 'heads', 'soup.', 'thistle', 'missed', 'odd', 'us.', 'involved', \"shiny?'\", 'join', 'creatures,', \"don't\", 'thousand', 'paw,', 'pointed', \"there,'\", 'recognised', 'surprise,', \"person!'\", 'yesterday,', 'can;', \"was,'\", 'if--if', '`some', 'time,', 'choosing', \"haven't\", 'measure', 'shorter,', '`mouse', '`sh!', 'jelly-fish', \"pig,'\", \"lessons!'\", 'swim.', \"whiskers!'\", 'man,', 'legs', 'hold', \"words.'\", 'fast', \"tale!'\", 'conger-eel,', 'continued,', 'alarm.', '`\"what', \"fact.'\", '`soo--oop', 'sobbing', 'manage', 'shedding', 'slowly', 'guess', \"others!'\", 'v', 'fluttered', 'spite', 'spread', 'commotion', 'corner', \"course,'\", 'violent', \"`you!'\", 'repeating', 'trumpet,', 'ask', 'ferrets!', \"australia?'\", 'seated', 'boy,', \"together.'\", '`this', 'arrived,', \"hatter.'\", \"prison,'\", 'aloud,', 'about;', \"whiting?'\", 'muchness--', 'kitchen,', 'form', 'tears,', 'ii', 'laughing:', 'is,', 'stretched', 'already,', 'father;', 'falling', 'people.', 'wag', 'unfortunate', 'round,', \"suppose.'\", 'tree', 'anxiously.', 'along', 'boy--and', \"accusation!'\", 'explanation.', 'been', 'attends', 'how', 'soup?', 'head!', 'usually', \"fun?'\", 'croquet', \"works!'\", 'constant', 'surprise', '`unimportant,', 'not.', 'came', 'curious', 'mark', 'prove', 'merely', 'completely.', 'arches.', \"sort!'\", 'little.', 'ago', 'doubtfully,', 'confusion,', 'do,', 'ran;', 'tail', 'birds,)', \"is!'\", 'whispers', \"were,'\", 'sage,', 'angry,', 'sulkily', 'content', \"time.'\", 'eating', 'hearts', '`well,', 'milk-jug', 'ran.', \"game's\", 'twelve?', 'attended', 'obliged', 'ordering', 'person,', 'baked', 'sell', 'case', 'writhing,', 'tortoise', 'thing', 'esq.', 'angrily.', \"remedies--'\", 'march,', '`after', 'children;', 'plates', 'other--bill!', 'beautiful', 'might,', 'submitted', 'livery', 'crimson', '`stupid', 'kick', 'nothing:', \"shoes.'\", \"`creatures,'\", 'sadly:--', \"axis--'\", 'around', 'camomile', 'dinah', \"idiotic!'\", 'elbows', 'half', 'wide,', 'happen:', 'crowd', \"yourself,'\", 'screaming', 'added', \"child?'\", 'reduced', 'edge', 'fact', 'flamingo,', 'stupid', \"lady,'\", 'ever', 'knelt', 'head--brandy', 'branches', \"mad?'\", 'ix', '`oh', 'two:', 'sharp', 'guinea-pigs,', 'moment.', 'beasts,', 'blows', '`for', 'shark,', 'coaxing.', 'advise', 'choking', 'fellow?', 'cheered.', 'well.', \"now!'\", 'they', \"`sixteenth,'\", 'its', \"queen!'\", 'next,', 'label,', \"so.'\", \"me'\", 'royal', 'bad', 'waters', 'judge,', 'accidentally', 'dodo', 'laughter.', 'xi', 'proper', '\"poison\"', 'lose', 'cross-examine', 'broken', \"lines!'\", 'occasionally;', \"`hadn't\", 'lory', 'wash', 'paper', 'behind', \"washing?'\", 'at', \"places!'\", 'watched', \"sh!'\", 'forepaws', \"judge,'\", \"stuff,'\", 'various', '`let', 'linked', 'cushion,', 'anxiously', 'said.', 'trembled', '\"coming', 'voice', 'door--', \"experiment?'\", 'all,', \"william's\", 'untwist', 'subdued', 'found', 'either,', '\"turtle', 'secondly,', \"he'll\", \"day--'\", 'same,', 'liked', 'cards,', 'hands', 'mixed', 'half-past', 'met', \"like?'\", \"confusing.'\", \"didn't\", 'rises', 'loving', 'small', 'stick,', \"alice!'\", 'day', 'pleaded', 'jumped', 'wore', \"words,'\", '`than', 'disappointment', 'highest', '`i--i', 'shilling', 'honest', 'claws', 'changed', 'fright', 'use,', '`however,', 'round!\"\\'', 'dark', 'run', '`--well', '`beautiful', 'about', \"said--'\", 'hid', \"remarks,'\", '\"such', 'snappishly.', 'beak--', 'station.)', 'friends', 'song.', 'machines', \"time!'\", 'directions', 'swallow', 'snail', \"dear!'\", 'been,', \"of?'\", 'sobs', 'carry', 'mouse', 'footsteps', 'civil,', 'history', \"`you'll\", 'william', 'through', '`are', 'last,', 'opposite', 'cake.', \"begin?'\", 'twice,', 'ought', 'size,', '\"william', 'neighbour', 'difficulty,', 'lie', 'as,', 'take', 'growl', 'eyes', 'apples,', \"sir'\", 'bent', 'far,', 'it,', \"hasn't\", 'latitude', 'splash!', \"couple?'\", \"prizes?'\", 'breathe', 'mustard', 'back,', 'subject.', \"important,'\", 'concert', 'only,', 'largest', 'end,', \"better,'\", \"seems,'\", \"that'll\", '`chorus', \"fourth.'\", \"yet--it's\", '`wake', \"things--'\", 'drowned', 'three,', \"trial.'\", 'lessen', 'arranged;', \"old,'\", '_i_', 'here!', 'rattle', 'saw', '`rule', 'true--\"', 'on.', 'sort', 'majesty', \"they'll\", \"different!'\", 'letters.', 'hard', 'conversation', 'dropped', 'whispered', 'custody', 'direction,', \"bit,'\", 'rate!', 'queer,', 'crown', 'oh!', 'appeared.', 'becoming.', 'repeated,', 'mournfully.', 'sink', 'is--\"be', \"a--i'm\", 'watching', 'either', '`keep', \"he's\", 'hoping', 'attending', 'loud.', 'chimney?--nay,', '`tut,', 'disobey,', 'change,', 'father,', 'game.', 'young', 'place', 'eagerly.', '(if', \"history,'\", 'raised', 'rearing', \"watch!'\", 'vi', 'face.', 'head--', 'timidly:', 'about,', 'courtiers,', '`but,', 'not', 'theirs,', \"you'll\", 'vanishing', 'otherwise.\"\\'', 'accounting', 'civil', \"pocket?'\", 'hurrying', 'witness.', 'poky', 'wild', 'course;', 'denied,', 'bones', 'deeply.', 'way.', 'under', \"footman's\", 'two.', 'tied', \"thimble,'\", 'parts', \"croquet?'\", 'foot!', 'terrier,', 'scaly', 'grunted', 'surprised', \"to,'\", 'washing--extra.\"\\'', 'dance.', 'cat', 'good-', \"begun.'\", 'you,', 'quiver', 'drawling,', 'should', 'seen', '`i', 'animals', 'straightening', 'push', \"present!'\", 'perhaps', \"from,'\", \"done,'\", 'farther', 'fairy-tales,', 'hatter:', \"t!'\", 'patriotic', 'immediate', 'tunnel', 'series', 'beat', 'schoolroom,', 'vulgar', 'question', 'pinch', 'question;', 'dig', 'act', \"away!'\", 'go?\"', 'side', \"thing!'\", \"crazy!'\", 'is--\"the', 'distance,', 'solemnly,', 'paws!', 'said;', 'grow', '\"there', '`nobody', 'severely.', '`did', 'breath,', 'tarts,', \"christmas.'\", \"now?'\", \"`let's\", 'would', 'ringlets,', 'safe', 'grumbled:', 'distance.', \"doesn't\", 'wrong,', '`nor', 'using', \"it!'\", 'milk', 'clever', 'catch', \"up.'\", 'pocket)', 'itself.', 'glanced', 'listened,', 'keeping', 'child', 'useful,', 'other.', 'adoption', 'crawling', 'once.', '`ah,', 'remark', 'beating.', 'above', \"better.'\", 'buttered', 'years,', 'mercia', 'executes', 'dance?', 'ear,', 'ears', 'maps', \"did!'\", \"hot-tempered,'\", \"onions.'\", 'cakes', 'normans--\"', 'while', \"hand,'\", 'butterfly,', 'which),', 'strange', '`on', 'grew', 'severity;', \"throat,'\", 'sends', \"whiting,'\", \"extras?'\", 'blown', 'pleasure', 'tops', 'hastily;', 'wrapping', \"certainly,'\", 'tortoise,', \"`it's--it's\", 'down,', 'roof.', 'consultation', 'them.', \"creatures,'\", \"i'll\", 'crossly:', 'needs', 'lazily', 'sneeze', \"pardon,'\", 'timidly,', 'grunted,', 'earnestly.', 'teacups', 'conversations', 'northumbria,', 'drive', 'ear', \"one's\", 'words:', 'question.', 'changing', 'ground,', \"offended!'\", 'move', 'guard', 'whiskers,', 'try', \"is?'\", \"now.'\", \"myself,'\", 'well!', 'meal,', 'sensation,', \"lesson-books!'\", 'learnt', 'below,', 'remarks', 'jurymen', \"dinah!'\", 'argue.', 'classics', 'mice', 'livery:', 'weak', 'toffee,', 'read', 'talking.', 'modern,', 'hearth', 'speech', 'sluggard,\"\\'', 'four', 'otherwise', 'miserable', \"haven't,'\", \"ann!'\", \"feet!'\", 'often', 'dreamy', 'king:', 'darkness', 'or', 'all;', 'down', 'interrupted:', 'enough', 'right;', 'failure.', \"stay!'\", 'no!', 'voice--the', 'ferrets', 'pepper-box', 'course--', '(`the', 'handed', 'lessons:', 'asked', 'tried.', \"done.'\", \"mine,'\", 'inclined', \"i'd\", 'salmon,', 'gryphon,', 'making', 'boots', 'long', 'straight', 'lizard)', '(he', 'wonderland', 'party.', \"about,'\", 'been.', \"down,'\", 'cup', 'clamour', 'teaching', 'till', '`stuff', \"rude.'\", \"size,'\", 'severely', 'there.', 'reply,', 'one--but', 'locks', 'executions', 'alice;', \"it.'\", 'precious', 'jar', 'coaxing', 'now!', 'asking,', 'happy', 'wags', 'further:', 'expecting', 'attempt', 'eyes.', \"instead!'\", 'we', 'sometimes', 'room!', 'high).', 'sending', 'slate.', 'quietly', \"me,'\", 'together:', 'master,', \"right,'\", 'well', 'two--\"', 'evening,', \"cats.'\", 'wanted', 'dreadful', 'leant', 'turns', 'chin:', 'growl,', 'yards', \"more.'\", 'livery,', '(sounds', 'much.', 'this:', 'seen--everything', \"perhaps?'\", 'archbishop', 'because', 'later.', 'politely;', 'trying', 'cause,', 'shoulders', 'were.', \"them!'\", 'fifteen', 'shriek', 'teapot.', 'humbly;', 'must', 'break.', 'simply', 'tale', 'hurry;', 'paint', 'close', 'undertone', 'puffed', '`\"we', \"clearly,'\", 'lesson-book.', 'fun', 'trickling', 'dance?\"\\'', \"`they're\", 'irritated', 'flower-pot', 'deep,', \"usual,'\", \"`she's\", 'flock', 'wrote', \"trial's\", 'cheerfully', 'barley-sugar', 'whereupon', 'chose', 'low', \"enough.'\", 'dare', \"won't\", 'purring', \"chose,'\", 'replied.', 'shrill,', 'politely,', 'though),', 'shrill', \"verse,'\", 'fall', 'within--a', 'right,', 'dear!', 'elsie,', 'minute,', 'belongs', 'mad.', 'porpoise?\"\\'', \"head!'\", 'fight', 'canterbury,', 'broken.', 'swallowing', 'parchment', 'line', 'people!', '`anything', 'kills', 'iv', 'vegetable.', 'rosetree;', 'presently', 'eels,', 'pulling', 'frowning', 'muchness\"--did', 'tea-party', 'like', 'smiling', 'must,'}\n",
            "Average sentence length: 7.4\n",
            "Vocabulary diversity: 0.1870\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.3 Text Preprocessing Pipeline"
      ],
      "metadata": {
        "id": "CFchkqMRe8Zg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Packages\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tag import pos_tag\n",
        "import nltk"
      ],
      "metadata": {
        "id": "VJ-g172a3uhI"
      },
      "execution_count": 363,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download required NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ASWlQvs33by",
        "outputId": "8fb2dc41-a71a-4a73-b228-ffb78400f893"
      },
      "execution_count": 364,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 364
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AdvancedTextPreprocessor:\n",
        "    \"\"\"Comprehensive text preprocessing for Word2Vec training\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 lowercase=True,\n",
        "                 remove_punctuation=True,\n",
        "                 remove_numbers=False,\n",
        "                 remove_stopwords=False,\n",
        "                 min_word_length=2,\n",
        "                 max_word_length=50,\n",
        "                 lemmatize=False,\n",
        "                 remove_urls=True,\n",
        "                 remove_emails=True,\n",
        "                 keep_sentences=True):\n",
        "\n",
        "        self.lowercase = lowercase\n",
        "        self.remove_punctuation = remove_punctuation\n",
        "        self.remove_numbers = remove_numbers\n",
        "        self.remove_stopwords = remove_stopwords\n",
        "        self.min_word_length = min_word_length\n",
        "        self.max_word_length = max_word_length\n",
        "        self.lemmatize = lemmatize\n",
        "        self.remove_urls = remove_urls\n",
        "        self.remove_emails = remove_emails\n",
        "        self.keep_sentences = keep_sentences\n",
        "\n",
        "        if remove_stopwords:\n",
        "            self.stop_words = set(stopwords.words('english'))\n",
        "\n",
        "        if lemmatize:\n",
        "            self.lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "    def clean_text(self, text):\n",
        "        \"\"\"Clean individual text string\"\"\"\n",
        "\n",
        "        # Remove URLs\n",
        "        if self.remove_urls:\n",
        "            text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "\n",
        "        # Remove email addresses\n",
        "        if self.remove_emails:\n",
        "            text = re.sub(r'\\S+@\\S+', '', text)\n",
        "\n",
        "        # Remove extra whitespace\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "        #Combined\n",
        "         #(r'https?://\\S+|www\\.\\S+|<.*?>|\\S+@\\S+\\.\\S+|@\\w+|#\\w+|[^A-Za-z0-9\\s])\n",
        "\n",
        "        return text\n",
        "\n",
        "    def tokenize_text(self, text):\n",
        "        \"\"\"Tokenize text into sentences or words\"\"\"\n",
        "\n",
        "        if self.keep_sentences:\n",
        "            # Tokenize into sentences first\n",
        "            sentences = sent_tokenize(text)\n",
        "            processed_sentences = []\n",
        "\n",
        "            for sentence in sentences:\n",
        "                words = self.process_sentence(sentence)\n",
        "                if len(words) >= 3:  # Keep sentences with at least 3 words\n",
        "                    processed_sentences.append(words)\n",
        "\n",
        "            return processed_sentences\n",
        "        else:\n",
        "            # Return single list of words\n",
        "            return self.process_sentence(text)\n",
        "\n",
        "    def process_sentence(self, sentence):\n",
        "        \"\"\"Process individual sentence\"\"\"\n",
        "\n",
        "        # Lowercase\n",
        "        if self.lowercase:\n",
        "            sentence = sentence.lower()\n",
        "\n",
        "        # Tokenize into words\n",
        "        words = word_tokenize(sentence)\n",
        "\n",
        "        processed_words = []\n",
        "        for word in words:\n",
        "\n",
        "            # Remove punctuation\n",
        "            if self.remove_punctuation:\n",
        "                word = word.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "            # Skip if empty after punctuation removal\n",
        "            if not word:\n",
        "                continue\n",
        "\n",
        "            # Remove numbers\n",
        "            if self.remove_numbers and word.isdigit():\n",
        "                continue\n",
        "\n",
        "            # Check word length\n",
        "            if len(word) < self.min_word_length or len(word) > self.max_word_length:\n",
        "                continue\n",
        "\n",
        "            # Remove stopwords\n",
        "            if self.remove_stopwords and word in self.stop_words:\n",
        "                continue\n",
        "\n",
        "            # Lemmatize\n",
        "            if self.lemmatize:\n",
        "                word = self.lemmatizer.lemmatize(word)\n",
        "\n",
        "            processed_words.append(word)\n",
        "\n",
        "        return processed_words\n",
        "\n",
        "    def preprocess_corpus(self, texts):\n",
        "        \"\"\"Preprocess entire corpus\"\"\"\n",
        "\n",
        "        all_sentences = []\n",
        "\n",
        "        for text in texts:\n",
        "            if not isinstance(text, str):\n",
        "                continue\n",
        "\n",
        "            # Clean text\n",
        "            cleaned_text = self.clean_text(text)\n",
        "\n",
        "            # Tokenize and process\n",
        "            processed = self.tokenize_text(cleaned_text)\n",
        "\n",
        "            if self.keep_sentences:\n",
        "                all_sentences.extend(processed)\n",
        "            else:\n",
        "                all_sentences.append(processed)\n",
        "\n",
        "        return all_sentences"
      ],
      "metadata": {
        "id": "s9lnl-HM38e8"
      },
      "execution_count": 365,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "preprocessor = AdvancedTextPreprocessor(\n",
        "    lowercase=True,\n",
        "    remove_punctuation = True,\n",
        "    remove_numbers=True,\n",
        "    remove_stopwords=False,  # Keep stopwords for Word2Vec\n",
        "    lemmatize=False,  # Usually not needed for Word2Vec\n",
        "    keep_sentences=True\n",
        ")\n",
        "\n",
        "# Processing corpus\n",
        "processed_sentences = preprocessor.preprocess_corpus(texts)\n",
        "print(f\"Processed {len(processed_sentences)} sentences\")\n",
        "print(f\"Sample sentence: {processed_sentences[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51iwom7s4ERJ",
        "outputId": "89ebfb12-dd73-445f-8738-39211a9c4c32"
      },
      "execution_count": 366,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 2941 sentences\n",
            "Sample sentence: ['alice', 'adventures', 'in', 'wonderland']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_sentences[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSRmMbLv4LZK",
        "outputId": "87ef6d90-adb5-4a4f-8316-9f9d6eba4800"
      },
      "execution_count": 367,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['alice', 'adventures', 'in', 'wonderland'],\n",
              " ['the', 'millennium', 'fulcrum', 'edition'],\n",
              " ['down', 'the', 'rabbithole']]"
            ]
          },
          "metadata": {},
          "execution_count": 367
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.4 Parameter Recommendation"
      ],
      "metadata": {
        "id": "WzEBZktKfBv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_parameters(corpus_size, vocab_size, domain_type, computing_resources):\n",
        "    \"\"\"\n",
        "    Recommend Word2Vec parameters based on corpus characteristics\n",
        "\n",
        "    Args:\n",
        "        corpus_size: Number of sentences/documents\n",
        "        vocab_size: Unique words in vocabulary\n",
        "        domain_type: 'general', 'technical', 'social_media', 'academic'\n",
        "        computing_resources: 'limited', 'moderate', 'high'\n",
        "    \"\"\"\n",
        "\n",
        "    recommendations = {}\n",
        "\n",
        "    # Vector size based on corpus and vocab size\n",
        "    if corpus_size < 10000:\n",
        "        recommendations['vector_size'] = 50\n",
        "    elif corpus_size < 100000:\n",
        "        recommendations['vector_size'] = 100\n",
        "    elif corpus_size < 1000000:\n",
        "        recommendations['vector_size'] = 200\n",
        "    else:\n",
        "        recommendations['vector_size'] = 300\n",
        "\n",
        "    # Window size based on domain\n",
        "    domain_windows = {\n",
        "        'general': 5,\n",
        "        'technical': 3,  # More syntactic focus\n",
        "        'social_media': 4,\n",
        "        'academic': 6    # More semantic focus\n",
        "    }\n",
        "    recommendations['window'] = domain_windows.get(domain_type, 5)\n",
        "\n",
        "    # Min count based on corpus size\n",
        "    if corpus_size < 10000:\n",
        "        recommendations['min_count'] = 1\n",
        "    elif corpus_size < 100000:\n",
        "        recommendations['min_count'] = 2\n",
        "    elif corpus_size < 1000000:\n",
        "        recommendations['min_count'] = 5\n",
        "    else:\n",
        "        recommendations['min_count'] = 10\n",
        "\n",
        "    # Algorithm selection\n",
        "    if domain_type in ['technical', 'academic']:\n",
        "        recommendations['sg'] = 1  # Skip-gram for rare technical terms\n",
        "    else:\n",
        "        recommendations['sg'] = 0  # CBOW for general text\n",
        "\n",
        "    # Epochs based on corpus size and resources\n",
        "    if computing_resources == 'limited':\n",
        "        recommendations['epochs'] = 5\n",
        "    elif corpus_size < 100000:\n",
        "        recommendations['epochs'] = 15\n",
        "    else:\n",
        "        recommendations['epochs'] = 10\n",
        "\n",
        "    # Hierarchical softmax vs negative sampling\n",
        "    if vocab_size > 100000:\n",
        "        recommendations['hs'] = 1\n",
        "        recommendations['negative'] = 0\n",
        "    else:\n",
        "        recommendations['hs'] = 0\n",
        "        recommendations['negative'] = 10\n",
        "\n",
        "    return recommendations"
      ],
      "metadata": {
        "id": "OYcnUQqT4Spf"
      },
      "execution_count": 368,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_size = len(processed_sentences)\n",
        "print(f\"Corpus Size: {corpus_size}\")\n",
        "\n",
        "# Calculate vocabulary size (unique words in vocabulary)\n",
        "vocab = set(word for sentence in processed_sentences for word in sentence)\n",
        "vocab_size = len(vocab)\n",
        "print(f\"Vocabulary Size: {vocab_size}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Devri0xE4WjM",
        "outputId": "4d566eca-a509-4458-9331-74e63df8aa00"
      },
      "execution_count": 369,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corpus Size: 2941\n",
            "Vocabulary Size: 2519\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For this task\n",
        "params = recommend_parameters(\n",
        "    corpus_size=corpus_size,\n",
        "    vocab_size=vocab_size,\n",
        "    domain_type='general',\n",
        "    computing_resources='moderate'\n",
        ")\n",
        "print(\"Recommended parameters:\", params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chMhl9qI4aeQ",
        "outputId": "2ae6326d-de94-441f-9a00-900ee75ac1e0"
      },
      "execution_count": 370,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommended parameters: {'vector_size': 50, 'window': 5, 'min_count': 1, 'sg': 0, 'epochs': 15, 'hs': 0, 'negative': 10}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.5 Word2Vec Training"
      ],
      "metadata": {
        "id": "3QRoErCtfH5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtYCDHpu4dYf",
        "outputId": "dcbfa37e-1a7d-456b-c996-cd7e539506ce"
      },
      "execution_count": 371,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.3.0.post1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "from gensim.models.callbacks import CallbackAny2Vec\n",
        "import time\n",
        "import multiprocessing\n",
        "\n",
        "class EpochLogger(CallbackAny2Vec):\n",
        "    \"\"\"Callback to log information about training progress\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.epoch = 0\n",
        "        self.start_time = time.time()\n",
        "\n",
        "    def on_epoch_begin(self, model):\n",
        "        print(f\"Epoch #{self.epoch} start\")\n",
        "\n",
        "    def on_epoch_end(self, model):\n",
        "        elapsed = time.time() - self.start_time\n",
        "        print(f\"Epoch #{self.epoch} end - Time elapsed: {elapsed:.2f}s\")\n",
        "        self.epoch += 1\n",
        "\n",
        "def train_word2vec_model(sentences, save_path=None, **params):\n",
        "    \"\"\"\n",
        "    Train Word2Vec model with given parameters\n",
        "\n",
        "    Args:\n",
        "        sentences: List of tokenized sentences\n",
        "        save_path: Path to save the model\n",
        "        **params: Word2Vec parameters\n",
        "    \"\"\"\n",
        "\n",
        "    # Set default parameters\n",
        "    default_params = {\n",
        "        'vector_size': 100,\n",
        "        'window': 5,\n",
        "        'min_count': 5,\n",
        "        'workers': multiprocessing.cpu_count() - 1,\n",
        "        'sg': 0,  # CBOW\n",
        "        'epochs': 10,\n",
        "        'alpha': 0.025,\n",
        "        'min_alpha': 0.0001,\n",
        "        'hs': 0,\n",
        "        'negative': 1\n",
        "    }\n",
        "\n",
        "    # Update with provided parameters\n",
        "    default_params.update(params)\n",
        "\n",
        "    print(\"Training Word2Vec model with parameters:\")\n",
        "    for key, value in default_params.items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "\n",
        "    # Add callback for progress monitoring\n",
        "    epoch_logger = EpochLogger()\n",
        "\n",
        "    # Train the model\n",
        "    print(f\"\\nTraining on {len(sentences)} sentences...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    model = Word2Vec(\n",
        "        sentences=sentences,\n",
        "        callbacks=[epoch_logger],\n",
        "        **default_params\n",
        "    )\n",
        "\n",
        "    training_time = time.time() - start_time\n",
        "    print(f\"\\nTraining completed in {training_time:.2f} seconds\")\n",
        "    print(f\"Vocabulary size: {len(model.wv)} words\")\n",
        "\n",
        "    # Save model if path provided\n",
        "    if save_path:\n",
        "        model.save(save_path)\n",
        "        print(f\"Model saved to {save_path}\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "y7hKkVXB4gBX"
      },
      "execution_count": 372,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "model = train_word2vec_model(\n",
        "    sentences=processed_sentences,\n",
        "    save_path='my_word2vec_model.model',\n",
        "    vector_size=150,\n",
        "    sg=1,\n",
        "    window=5,\n",
        "    min_count=1,\n",
        "    epochs=50,\n",
        "    negative=15,\n",
        "    compute_loss = True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hxH9kLF562o",
        "outputId": "1fe87995-c5e4-4d74-944d-adc3b09a8e38"
      },
      "execution_count": 373,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Word2Vec model with parameters:\n",
            "  vector_size: 150\n",
            "  window: 5\n",
            "  min_count: 1\n",
            "  workers: 1\n",
            "  sg: 1\n",
            "  epochs: 50\n",
            "  alpha: 0.025\n",
            "  min_alpha: 0.0001\n",
            "  hs: 0\n",
            "  negative: 15\n",
            "  compute_loss: True\n",
            "\n",
            "Training on 2941 sentences...\n",
            "Epoch #0 start\n",
            "Epoch #0 end - Time elapsed: 0.31s\n",
            "Epoch #1 start\n",
            "Epoch #1 end - Time elapsed: 0.72s\n",
            "Epoch #2 start\n",
            "Epoch #2 end - Time elapsed: 1.05s\n",
            "Epoch #3 start\n",
            "Epoch #3 end - Time elapsed: 1.33s\n",
            "Epoch #4 start\n",
            "Epoch #4 end - Time elapsed: 1.72s\n",
            "Epoch #5 start\n",
            "Epoch #5 end - Time elapsed: 1.98s\n",
            "Epoch #6 start\n",
            "Epoch #6 end - Time elapsed: 2.24s\n",
            "Epoch #7 start\n",
            "Epoch #7 end - Time elapsed: 2.75s\n",
            "Epoch #8 start\n",
            "Epoch #8 end - Time elapsed: 3.20s\n",
            "Epoch #9 start\n",
            "Epoch #9 end - Time elapsed: 3.68s\n",
            "Epoch #10 start\n",
            "Epoch #10 end - Time elapsed: 4.21s\n",
            "Epoch #11 start\n",
            "Epoch #11 end - Time elapsed: 5.01s\n",
            "Epoch #12 start\n",
            "Epoch #12 end - Time elapsed: 5.82s\n",
            "Epoch #13 start\n",
            "Epoch #13 end - Time elapsed: 6.35s\n",
            "Epoch #14 start\n",
            "Epoch #14 end - Time elapsed: 7.25s\n",
            "Epoch #15 start\n",
            "Epoch #15 end - Time elapsed: 8.28s\n",
            "Epoch #16 start\n",
            "Epoch #16 end - Time elapsed: 8.88s\n",
            "Epoch #17 start\n",
            "Epoch #17 end - Time elapsed: 9.72s\n",
            "Epoch #18 start\n",
            "Epoch #18 end - Time elapsed: 10.96s\n",
            "Epoch #19 start\n",
            "Epoch #19 end - Time elapsed: 11.97s\n",
            "Epoch #20 start\n",
            "Epoch #20 end - Time elapsed: 12.52s\n",
            "Epoch #21 start\n",
            "Epoch #21 end - Time elapsed: 12.97s\n",
            "Epoch #22 start\n",
            "Epoch #22 end - Time elapsed: 13.48s\n",
            "Epoch #23 start\n",
            "Epoch #23 end - Time elapsed: 14.10s\n",
            "Epoch #24 start\n",
            "Epoch #24 end - Time elapsed: 14.75s\n",
            "Epoch #25 start\n",
            "Epoch #25 end - Time elapsed: 15.16s\n",
            "Epoch #26 start\n",
            "Epoch #26 end - Time elapsed: 15.76s\n",
            "Epoch #27 start\n",
            "Epoch #27 end - Time elapsed: 16.36s\n",
            "Epoch #28 start\n",
            "Epoch #28 end - Time elapsed: 16.95s\n",
            "Epoch #29 start\n",
            "Epoch #29 end - Time elapsed: 17.54s\n",
            "Epoch #30 start\n",
            "Epoch #30 end - Time elapsed: 18.02s\n",
            "Epoch #31 start\n",
            "Epoch #31 end - Time elapsed: 18.50s\n",
            "Epoch #32 start\n",
            "Epoch #32 end - Time elapsed: 19.09s\n",
            "Epoch #33 start\n",
            "Epoch #33 end - Time elapsed: 19.55s\n",
            "Epoch #34 start\n",
            "Epoch #34 end - Time elapsed: 19.91s\n",
            "Epoch #35 start\n",
            "Epoch #35 end - Time elapsed: 20.17s\n",
            "Epoch #36 start\n",
            "Epoch #36 end - Time elapsed: 20.44s\n",
            "Epoch #37 start\n",
            "Epoch #37 end - Time elapsed: 20.69s\n",
            "Epoch #38 start\n",
            "Epoch #38 end - Time elapsed: 20.96s\n",
            "Epoch #39 start\n",
            "Epoch #39 end - Time elapsed: 21.21s\n",
            "Epoch #40 start\n",
            "Epoch #40 end - Time elapsed: 21.50s\n",
            "Epoch #41 start\n",
            "Epoch #41 end - Time elapsed: 21.91s\n",
            "Epoch #42 start\n",
            "Epoch #42 end - Time elapsed: 22.31s\n",
            "Epoch #43 start\n",
            "Epoch #43 end - Time elapsed: 22.70s\n",
            "Epoch #44 start\n",
            "Epoch #44 end - Time elapsed: 23.11s\n",
            "Epoch #45 start\n",
            "Epoch #45 end - Time elapsed: 23.50s\n",
            "Epoch #46 start\n",
            "Epoch #46 end - Time elapsed: 23.88s\n",
            "Epoch #47 start\n",
            "Epoch #47 end - Time elapsed: 24.28s\n",
            "Epoch #48 start\n",
            "Epoch #48 end - Time elapsed: 24.66s\n",
            "Epoch #49 start\n",
            "Epoch #49 end - Time elapsed: 25.05s\n",
            "\n",
            "Training completed in 25.05 seconds\n",
            "Vocabulary size: 2519 words\n",
            "Model saved to my_word2vec_model.model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(model.wv.index_to_key)\n",
        "print(\"Vocabulary Size:\", vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pshlXXs5_jz",
        "outputId": "48e01ae6-2485-4e5a-953d-dbdedb30ab04"
      },
      "execution_count": 374,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary Size: 2519\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_words = model.wv.index_to_key\n",
        "print(\"All Words in Vocabulary:\", all_words[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tv4S3k8e7-0P",
        "outputId": "eff351dd-9ea9-45b5-e404-6dc65a6d7694"
      },
      "execution_count": 375,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All Words in Vocabulary: ['the', 'and', 'to', 'it', 'she', 'of', 'said', 'you', 'in', 'was']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.6 Model Evaluation"
      ],
      "metadata": {
        "id": "7Qi3Ml5BfkcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import spearmanr\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "class Word2VecEvaluator:\n",
        "    \"\"\"Comprehensive evaluation suite for Word2Vec models\"\"\"\n",
        "\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        self.wv = model.wv\n",
        "\n",
        "    def evaluate_word_similarity(self, word_pairs_with_scores):\n",
        "        \"\"\"\n",
        "        Evaluate model on word similarity datasets\n",
        "\n",
        "        Args:\n",
        "            word_pairs_with_scores: List of tuples (word1, word2, human_score)\n",
        "\n",
        "        Returns:\n",
        "            Spearman correlation with human judgments\n",
        "        \"\"\"\n",
        "\n",
        "        model_similarities = []\n",
        "        human_similarities = []\n",
        "\n",
        "        for word1, word2, human_score in word_pairs_with_scores:\n",
        "            try:\n",
        "                model_sim = self.wv.similarity(word1, word2)\n",
        "                model_similarities.append(model_sim)\n",
        "                human_similarities.append(human_score)\n",
        "            except KeyError:\n",
        "                # Skip if words not in vocabulary\n",
        "                continue\n",
        "\n",
        "        if len(model_similarities) < 10:\n",
        "            print(\"Warning: Too few valid word pairs for reliable evaluation\")\n",
        "            return None\n",
        "\n",
        "        correlation, p_value = spearmanr(human_similarities, model_similarities)\n",
        "\n",
        "        print(f\"Word Similarity Evaluation:\")\n",
        "        print(f\"Valid pairs: {len(model_similarities)}\")\n",
        "        print(f\"Spearman correlation: {correlation:.4f}\")\n",
        "        print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "        return correlation\n",
        "\n",
        "    def evaluate_analogies(self, analogy_dataset):\n",
        "        \"\"\"\n",
        "        Evaluate model on word analogy tasks\n",
        "\n",
        "        Args:\n",
        "            analogy_dataset: List of tuples (word_a, word_b, word_c, word_d)\n",
        "                           representing \"word_a is to word_b as word_c is to word_d\"\n",
        "\n",
        "        Returns:\n",
        "            Accuracy on analogy task\n",
        "        \"\"\"\n",
        "\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        #('king', 'queen', 'man', 'woman'),\n",
        "        for word_a, word_b, word_c, expected_d in analogy_dataset:\n",
        "            try:\n",
        "                # Predict word_d\n",
        "                result = self.wv.most_similar(\n",
        "                    positive=[word_a, word_b],\n",
        "                    negative=[word_c],\n",
        "                    topn=1\n",
        "                )\n",
        "\n",
        "                predicted_d = result\n",
        "\n",
        "                if predicted_d[0][0].lower() == expected_d.lower():\n",
        "                    correct += 1\n",
        "\n",
        "                total += 1\n",
        "\n",
        "            except (KeyError, IndexError):\n",
        "                # Skip if words not in vocabulary\n",
        "                continue\n",
        "\n",
        "        if total == 0:\n",
        "            print(\"Warning: No valid analogies found\")\n",
        "            return 0\n",
        "\n",
        "        accuracy = correct / total\n",
        "\n",
        "        print(f\"Analogy Evaluation:\")\n",
        "        print(f\"Valid analogies: {total}\")\n",
        "        print(f\"Correct predictions: {correct}\")\n",
        "        print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "        return accuracy\n",
        "\n",
        "    def evaluate_odd_one_out(self, word_groups):\n",
        "        \"\"\"\n",
        "        Evaluate model's ability to identify odd words in groups\n",
        "\n",
        "        Args:\n",
        "            word_groups: List of lists, each containing words where one doesn't belong\n",
        "\n",
        "        Returns:\n",
        "            Accuracy on odd-one-out task\n",
        "        \"\"\"\n",
        "\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for group in word_groups:\n",
        "            if len(group) < 3:\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                # Find the word that doesn't match others\n",
        "                odd_word = self.wv.doesnt_match(group)\n",
        "\n",
        "                # This is tricky - we need ground truth to evaluate properly\n",
        "                # For now, just check if the model can identify AN odd word\n",
        "                correct += 1  # Placeholder - you'd need labeled data\n",
        "                total += 1\n",
        "\n",
        "            except KeyError:\n",
        "                continue\n",
        "\n",
        "        if total == 0:\n",
        "            return 0\n",
        "\n",
        "        accuracy = correct / total\n",
        "\n",
        "        print(f\"Odd-One-Out Evaluation:\")\n",
        "        print(f\"  Valid groups: {total}\")\n",
        "        print(f\"  Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "        return accuracy\n",
        "\n",
        "    def analyze_vocabulary_coverage(self, test_texts):\n",
        "        \"\"\"\n",
        "        Analyze how well model vocabulary covers test texts\n",
        "\n",
        "        Args:\n",
        "            test_texts: List of text strings\n",
        "\n",
        "        Returns:\n",
        "            Coverage statistics\n",
        "        \"\"\"\n",
        "\n",
        "        vocab = set(self.wv.index_to_key)\n",
        "\n",
        "        total_words = 0\n",
        "        covered_words = 0\n",
        "        unknown_words = set()\n",
        "\n",
        "        for text in test_texts:\n",
        "            words = text.lower().split()\n",
        "            total_words += len(words)\n",
        "\n",
        "            for word in words:\n",
        "                if word in vocab:\n",
        "                    covered_words += 1\n",
        "                else:\n",
        "                    unknown_words.add(word)\n",
        "\n",
        "        coverage_ratio = covered_words / total_words if total_words > 0 else 0\n",
        "\n",
        "        print(f\"Vocabulary Coverage Analysis:\")\n",
        "        print(f\"  Total words in test: {total_words}\")\n",
        "        print(f\"  Covered words: {covered_words}\")\n",
        "        print(f\"  Coverage ratio: {coverage_ratio:.4f}\")\n",
        "        print(f\"  Unknown words: {len(unknown_words)}\")\n",
        "\n",
        "        return {\n",
        "            'coverage_ratio': coverage_ratio,\n",
        "            'unknown_words': list(unknown_words)[:20],  # Show first 20\n",
        "            'total_unknown': len(unknown_words)\n",
        "        }\n",
        "\n",
        "    def compare_with_baseline(self, baseline_model, test_words):\n",
        "        \"\"\"\n",
        "        Compare model performance with baseline model\n",
        "\n",
        "        Args:\n",
        "            baseline_model: Another Word2Vec model to compare against\n",
        "            test_words: List of words to test\n",
        "\n",
        "        Returns:\n",
        "            Comparison statistics\n",
        "        \"\"\"\n",
        "\n",
        "        common_words = []\n",
        "        for word in test_words:\n",
        "            if word in self.wv and word in baseline_model.wv:\n",
        "                common_words.append(word)\n",
        "\n",
        "        if len(common_words) < 10:\n",
        "            print(\"Warning: Too few common words for reliable comparison\")\n",
        "            return None\n",
        "\n",
        "        # Compare similarity patterns\n",
        "        similarities = []\n",
        "\n",
        "        for i, word1 in enumerate(common_words[:20]):  # Test subset\n",
        "            for word2 in common_words[i+1:21]:  # Avoid too many comparisons\n",
        "\n",
        "                sim1 = self.wv.similarity(word1, word2)\n",
        "                sim2 = baseline_model.wv.similarity(word1, word2)\n",
        "\n",
        "                similarities.append((sim1, sim2))\n",
        "\n",
        "        model_sims = [s for s in similarities]\n",
        "        baseline_sims = [s for s in similarities]\n",
        "\n",
        "        correlation, _ = spearmanr(model_sims, baseline_sims)\n",
        "\n",
        "        print(f\"Model Comparison:\")\n",
        "        print(f\"  Common vocabulary: {len(common_words)}\")\n",
        "        print(f\"  Similarity correlation: {correlation:.4f}\")\n",
        "\n",
        "        return correlation"
      ],
      "metadata": {
        "id": "lyhJo61_8CG5"
      },
      "execution_count": 376,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example evaluation datasets\n",
        "word_similarity_pairs = [\n",
        "    ('king', 'queen', 8.5),\n",
        "    ('man', 'woman', 8.3),\n",
        "    ('car', 'automobile', 9.2),\n",
        "    ('computer', 'laptop', 7.8),\n",
        "    ('cat', 'dog', 6.1),\n",
        "    ('happy', 'sad', 2.1),\n",
        "]\n",
        "\n",
        "analogy_examples = [\n",
        "    ('king', 'queen', 'man', 'woman'),\n",
        "    ('paris', 'france', 'london', 'england'),\n",
        "    ('walking', 'walked', 'running', 'ran'),\n",
        "    ('good', 'better', 'bad', 'worse'),\n",
        "]\n",
        "\n",
        "# Usage example\n",
        "evaluator = Word2VecEvaluator(model)\n",
        "sim_score = evaluator.evaluate_word_similarity(word_similarity_pairs)\n",
        "analogy_score = evaluator.evaluate_analogies(analogy_examples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbLrvuKA8GEr",
        "outputId": "9618e5a7-e449-4733-abe1-cb3d75ef517c"
      },
      "execution_count": 377,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Too few valid word pairs for reliable evaluation\n",
            "Analogy Evaluation:\n",
            "Valid analogies: 4\n",
            "Correct predictions: 1\n",
            "Accuracy: 0.2500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word = \"alice\"\n",
        "if word in model.wv:\n",
        "    similar_words = model.wv.most_similar(word, topn=10)\n",
        "    print(f\"Most similar words to '{word}':\")\n",
        "    for similar_word, similarity in similar_words:\n",
        "        print(f\"{similar_word}: {similarity}\")\n",
        "else:\n",
        "    print(\"Word is not in the vocabulary.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fs37wA2V8IRt",
        "outputId": "f9bf6f69-0961-4ebe-c684-5eee8adbc125"
      },
      "execution_count": 378,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most similar words to 'alice':\n",
            "pleasanter: 0.5840699076652527\n",
            "uncivil: 0.5828311443328857\n",
            "bite: 0.5790944695472717\n",
            "thoughtfully: 0.5629265904426575\n",
            "cautiously: 0.5575256943702698\n",
            "she: 0.552374541759491\n",
            "natured: 0.55105060338974\n",
            "alarmed: 0.5438852310180664\n",
            "uncomfortable: 0.5390052795410156\n",
            "desperate: 0.5313905477523804\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.similarity('king', 'queen')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLtoOGLf8NtV",
        "outputId": "7a93775b-05b2-4b35-c388-60bffe20f481"
      },
      "execution_count": 379,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2621888"
            ]
          },
          "metadata": {},
          "execution_count": 379
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.similarity('good', 'worse')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__v0fuvQ8Q6d",
        "outputId": "f5fb3ba1-ca24-454b-f867-09e6645ae4c2"
      },
      "execution_count": 380,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5239563"
            ]
          },
          "metadata": {},
          "execution_count": 380
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## THANK YOU"
      ],
      "metadata": {
        "id": "QQReVU33ftQ-"
      }
    }
  ]
}